{
  "2504.13181": {
    "summary": "The Perception Encoder (PE) is a state-of-the-art image and video understanding encoder that uses contrastive vision-language training to produce strong, general embeddings for various downstream tasks.",
    "keywords": "perception encoder, contrastive learning, vision-language training, image understanding, video understanding."
  },
  "2103.14030": {
    "summary": "This research presents a new vision Transformer, called Swin Transformer, which serves as a general-purpose backbone for computer vision tasks such as image classification and dense prediction tasks.",
    "keywords": "Vision Transformer, Computer Vision, Shifted Windows, Hierarchical Architecture."
  },
  "1706.03762": {
    "summary": "A new neural network architecture called the Transformer, based solely on attention mechanisms, outperforms existing models in machine translation tasks while being more parallelizable and requiring less training time.",
    "keywords": "transformer, attention mechanism, machine translation, recurrence, convolution."
  }
}