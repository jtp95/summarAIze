{"1": "Hand-waving and Interpretive Dance:\nAn Introductory Course on Tensor Networks\nLecture Notes\nJacob C. Bridgeman1, Christopher T. Chubb2\nCentre for Engineered Quantum Systems\nSchool of Physics, The University of Sydney, Sydney, Australia\nAustralian Institute of Nanoscale Science and Technology\nSydney Nanoscience Hub, The University of Sydney, Sydney, Australia\nVersion 4, May 17, 2017\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\n1jacob.bridgeman@sydney.edu.au, http://www.physics.usyd.edu.au/~jbridge\n2christopher.chubb@sydney.edu.au, http://www.physics.usyd.edu.au/~cchubb\narXiv:1603.03039v4  [quant-ph]  16 May 2017\n", "2": "Abstract\nThe curse of dimensionality associated with the Hilbert space of spin systems provides a signi\ufb01cant\nobstruction to the study of condensed matter systems. Tensor networks have proven an important\ntool in attempting to overcome this di\ufb03culty in both the numerical and analytic regimes.\nThese notes form the basis for a seven lecture course, introducing the basics of a range of com-\nmon tensor networks and algorithms. In particular, we cover: introductory tensor network notation,\napplications to quantum information, basic properties of matrix product states, a classi\ufb01cation of\nquantum phases using tensor networks, algorithms for \ufb01nding matrix product states, basic properties\nof projected entangled pair states, and multiscale entanglement renormalisation ansatz states.\nThe lectures are intended to be generally accessible, although the relevance of many of the examples\nmay be lost on students without a background in many-body physics/quantum information. For each\nlecture, several problems are given, with worked solutions in an ancillary \ufb01le.\nAcknowledgements\nWe thank everyone who stayed awake for the presentation of these lectures in January of 2016 at\nthe Australian Institute of Nanoscience. We thank Stephen Bartlett, Andrew Doherty, Christopher\nGranade, Robin Harper, Marco Tomamichel, Dominic Williamson, and especially Doriane Drolet and\nDavid Tuckett, for their input. For suggesting that we give these lectures and editorial assistance,\nwe give special thanks for the best-selling childrens\u2019 author1 Chris Ferrie. We acknowledge support\nfrom the Australian Research Council via the Centre of Excellence in Engineered Quantum Systems\n(EQuS), project number CE110001013.\nMuch of the material was reproduced from memory after one of the authors attended the Tensor\nNetwork Summer School at Universiteit Gent in 2015.\n1Source 1, Source 2.\n", "3": "Contents\n0\nIntroduction\n3\n1\nIntroduction to Tensor Network Notation\n4\n1.1\nTensors\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.2\nTensor operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.2.1\nTensor product . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.2.2\nTrace\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.2.3\nContraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.2.4\nGrouping and splitting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\nAside 1: Why do we care so much about the singular value decomposition?\n. . . . . .\n7\n1.3\nTensor networks\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.4\nBubbling\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.5\nComputational Complexity\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n1.6\nProblems\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n1.7\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n2\nQuantum information examples\n12\n2.1\nBell state and the Bell basis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n2.2\nQuantum Teleportation\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n2.2.1\nGate Teleportation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n2.3\nPuri\ufb01cation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n2.4\nStinespring\u2019s Dilation Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n2.5\nProblems\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n2.6\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3\nMatrix Product States\n16\n3.1\n1D Projected Entangled Pair States\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.2\nSome MPS states . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.3\nMPS Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.3.1\nDecay of Correlations\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.3.2\nGauge Freedom . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n3.4\nRenormalising Matrix Product States\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.5\nMixed States and Many Body Operators . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.6\nProblems\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3.7\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4\nClassifying Gapped Phases in 1D\n26\n4.1\nQuantum Phases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n4.2\nInjective MPS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\n4.3\nNo Topological Order\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\n4.4\nSymmetry Respecting Phases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\nAside 2: Projective representations . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n4.5\nProblems\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n4.6\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n5\nTensor network algorithms\n35\n5.1\nDMRG (The Computer Scientist\u2019s approach)\n. . . . . . . . . . . . . . . . . . . . . . .\n35\n5.1.1\nOne-site . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n5.1.2\nTwo-site . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n37\n5.2\nTEBD (The Physicist\u2019s approach)\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n37\n5.3\nImplementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n5.4\nProblems\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n5.5\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\n1\n", "4": "6\nProjected Entangled Pair States\n41\n6.1\nOne Dimensional Systems: MPS\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n41\n6.2\nExtending to Higher Dimensions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n41\n6.3\nSome PEPS examples\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n42\nAside 3: Kitaev\u2019s Toric code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n43\n6.4\n2D Cluster State and the complexity of PEPS . . . . . . . . . . . . . . . . . . . . . . .\n46\n6.4.1\nNumerical PEPS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n46\n6.5\nProperties of PEPS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n47\nAside 4: Tensor network for classical partition function . . . . . . . . . . . . . . . . . .\n47\n6.5.1\nAlgebraic decay of correlations . . . . . . . . . . . . . . . . . . . . . . . . . . .\n48\n6.5.2\nGauge freedom . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n49\n6.6\nProblems\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n49\n6.7\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n49\n7\nMultiscale Entanglement Renormalisation Ansatz\n51\n7.1\nProperties of MERA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n51\n7.2\nRenormalisation Group Transformation\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n7.3\nAdS/CFT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n54\n7.4\nSome Simple MERA States . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n54\n7.5\nProblems\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n56\n7.6\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n56\nA PEPOs for local Hamiltonians: The \u2018particle decay\u2019 construction\n58\nA.1 1D . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n58\nA.2 2D and higher . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n59\nA.3 Other examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n60\nA.4 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n60\n2\n", "5": "0\nIntroduction\nOne of the biggest obstacles to the theoretical and numerical study of quantum many-body systems\nis the curse of dimensionality, the exponential growth of the Hilbert space of quantum states. In\ngeneral this curse prevents e\ufb03cient description of states, providing a signi\ufb01cant complexity barrier to\ntheir study. Despite this, physically relevant states often possess additional structure not found in\narbitrary states, and as such do not exhibit this pathological complexity, allowing them to be e\ufb03ciently\ndescribed and studied.\nTensor networks have proven to be an incredibly important technique in studying condensed matter\nsystems, with much of the modern theory and numerics used to study these systems involving tensor\nnetworks.\nIn the numerical regime, tensor networks provide variational classes of states which can be e\ufb03-\nciently described. By, for example, minimising the energy over one of these classes, one can learn a\ngreat deal about the low-energy behaviour some physical system of interest. The key variational classes\nare: matrix product states (MPS), projected entangled pair states (PEPS), and multiscale entangle-\nment renormalisation ansatz (MERA). Due to their importance, and prevalence in the literature, we\ndevote a chapter to each of these.\nBy studying the structure and properties of classes tensor networks, for example MPS, one can\nlearn a great deal about the types of states which they can describe. Tensor network states therefore\nprovide an important analytic framework for understanding the universal properties of classes of\nstates which possess particular properties, such as those which only support certain entanglement or\ncorrelation structures.\nIn addition to their application to many-body physics, tensor networks can also be used to under-\nstand many of the foundational results in quantum information. The understanding of concepts such\nas quantum teleportation, puri\ufb01cation, and the church of the larger Hilbert space, can be understood\nrelatively simply when the tensor network framework is utilised. Some examples of this are presented\nin Section 2. These lectures aim to introduce, and make familiar, the notation conventionally used for\ntensor network calculations. As a warm up, we present some key quantum information results in this\nnotation.\nAfter introducing the class of MPS, we present some of the key properties, as well as several\nanalytic matrix product states examples, which can serve as useful toy models. To demonstrate the\nanalytic power of MPS we will then consider a key result in condensed matter theory: the classi\ufb01cation\nof one-dimensional phases. This serves as an example of a result which, within the tensor network\nformalism, can be much more succinctly and clearly explained than it can in more standard linear\nalgebraic notation.\nWhen utilising tensor networks numerically, algorithms must be designed which, for example,\nminimise the energy of some Hamiltonian over the variational class. We introduce two such algorithms,\nnamely DMRG and TEBD, which are particularly prevalent. These have become standard tools in\nnumerical many-body physics.\nWe then introduce the class of PEPS, a class designed for two-dimensional many-body systems. We\ndiscuss some of the properties, and some of the challenges to simulating using this class of networks.\nFinally, we introduce another class, MERA, which can be utilised for the study of gapless one-\ndimensional (and higher!) systems. This class has many interesting properties, including an interpre-\ntation as a renormalisation group. This has sparked interest in a wide range of \ufb01eld, from quantum\ninformation to string theory.\n3\n", "6": "1\nIntroduction to Tensor Network Notation\nOne of the primary reasons that tensor networks are so useful is the straightforward and transparent\nnotation usually used to describe them. Using a graphical language, the structure is manifest. Many\ngeneral properties of the objects under study, particularly quantum states, can be identi\ufb01ed directly\nfrom the structure of the network needed to describe them.\nTensor network notation (TNN) can be considered a generalisation of Einstein summation nota-\ntion. In this lecture we will de\ufb01ne tensor networks, starting with an introduction to tensors and the\noperations we can perform upon them.\n1.1\nTensors\nTensors are a generalisation of vectors and matrices. A d-dimensional vector can be considered an\nelement of Cd, and a n\u00d7m-dimensional matrix an element of Cn\u00d7m. Correspondingly a rank-r tensor\nof dimensions d1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 dr is an element of Cd1\u00d7\u00b7\u00b7\u00b7\u00d7dr. We can clearly see that scalars, vectors and\nmatrices are all therefore rank 0, 1 and 2 tensors respectively.\nIn tensor network notation a single tensor is simply represented by a geometric shape with legs\nsticking out of it, each corresponding to an index, analogous to the indices of Einstein notation. For\nexample a rank-four tensor R would be represented as\nR\u03c1\n\u03c3\u00b5\u03bd =\u21d2\nR .\n(1.1)\nIn some contexts the shape used and direction of the legs can imply certain properties of the tensor\nor index \u2014 for a general network however, neither carry any special signi\ufb01cance. When representing\nquantum states, it is often convenient to use the direction of legs to denote whether the corresponding\nvectors live in the Hilbert space (\u2018kets\u2019) or its dual (\u2018bras\u2019). By adhering to this convention, certain\nprohibited contractions can be easily disallowed, such as contraction between two kets. This is no-\ntationally analogous to the convention of upper and lower denoting co- and contra-variant indices in\nEinstein or Penrose notation (a specialised form of TNN) employed in the study of general relativity\nor quantum \ufb01eld theory.\nBecause quantum mechanics, in contrast to general relativity, is complex, care has to be taken with\ncomplex conjugation. This is usually indicated either by explicitly labelling the tensor or adopting some\nindex convention, such as \ufb02ipping a network (upward and downward legs being echanged) carrying an\nimplicit conjugation.\n1.2\nTensor operations\nThe main advantage in TNN comes in representing tensors that are themselves composed of several\nother tensors. The two main operations we will consider are those of the tensor product and trace,\ntypically used in the joint operation of contraction. As well as these two operations, the rank of a\ntensor can be altered by grouping/splitting indices.\n1.2.1\nTensor product\nThe \ufb01rst operation we will consider is the tensor product, a generalisation of the outer product of\nvectors. The value of the tensor product on a given set of indices is the element-wise product of the\nvalues of each constituent tensor. Explicitly written out in index notation, the binary tensor product\nhas the form:\n[A \u2297B]i1,...,ir,j1,...,js :=Ai1,...,ir \u00b7 Bj1,...,js .\n(1.2)\nDiagrammatically the tensor product is simply represented by two tensors being placed next to each\nother. As such the value of a network containing disjoint tensors is simply the product of the con-\nstituent values.\n4\n", "7": "A\nB\n:=\nA \u2297B\n(1.3)\n1.2.2\nTrace\nThe next operation is that of the (partial) trace. Given a tensor A, for which the xth and yth indices\nhave identical dimensions (dx = dy), the partial trace over these two dimensions is simply a joint\nsummation over that index:\n[Trx,y A]i1,...,ix\u22121,ix+1,...,iy\u22121,iy+1,...,ir =\ndx\nX\n\u03b1=1\nAi1,...,ix\u22121,\u03b1,ix+1,...,iy\u22121,\u03b1,iy+1,...,ir\n(1.4)\nSimilar to Einstein notation, this summation is implicit in TNN, indicated by the corresponding legs\nbeing joined. An advantage over Einstein notation is that these summed-over indices need not be\nnamed, making the notation less clunky for large networks. For example, consider tracing over the\ntwo indices of a rank-3 tensor:\n:= TrRight\n\u0012\n\u0013\n=\nX\ni\ni\ni\n(1.5)\nOne property of the trace we can trivially see from this notation is that of its cyclic property.\nBy simply sliding one of the matrices around \u2013 which only changes the placement of the tensors\nin the network, and therefore not the value \u2013 we can cycle the matrices around (being careful of\ntranspositions), proving Tr(AB) = Tr(BA).\nTr(AB) =\nA\nB\n=\nA\nB\n=\nA\nBT\n=\nB\nA\n= Tr(BA)\n(1.6)\nWhilst this serves as a trivial example, the higher rank equivalents of this statement are not always\nso obvious, and the fact that these properties hold \u2018more obviously\u2019 in TNN is often useful.\n1.2.3\nContraction\nThe most common tensor operation used is contraction, corresponding to a tensor product followed by\na trace between indices of the two tensors. An example would be the contraction between two pairs\nof indices of two rank-3 tensors, which is drawn as:\n:=\nX\ni,j\ni\nj\nj\ni\n(1.7)\nFamiliar examples of contraction are vector inner products, matrix-vector multiplication, matrix-\nmatrix multiplication, and the trace of a matrix:\nConventional\nEinstein\nTNN\n\u27e8\u20d7x, \u20d7y\u27e9\nx\u03b1y\u03b1\nx\ny\nM\u20d7v\nM\u03b1\n\u03b2v\u03b2\nM\nv\nAB\nA\u03b1\n\u03b2B\u03b2\n\u03b3\nA\nB\nTr(X)\nX\u03b1\n\u03b1\nX\n5\n", "8": "1.2.4\nGrouping and splitting\nRank is a rather \ufb02uid concept in the study of tensor networks. The space of tensors Ca1\u00d7\u00b7\u00b7\u00b7\u00d7an and\nCb1\u00d7\u00b7\u00b7\u00b7\u00d7bm are isomorphic as vector spaces whenever the overall dimensions match (Q\ni ai = Q\ni bi).\nUsing this we can extend concepts and techniques only previously de\ufb01ned for vectors and matrices\nto all tensors. To do this, we can group or split indices to lower or raise the rank of a given tensor\nrespectively.\nConsider the case of contracting two arbitrary tensors. If we group together the indices which are\nand are not involved in this contraction, this procedure simply reduces to matrix multiplication:\n=\n=\n(1.8)\nIt should be noted that not only is this reduction to matrix multiplication pedagogically handy, but\nthis is precisely the manner in which numerical tensor packages perform contraction, allowing them\nto leverage highly optimised matrix multiplication code.\nOwing to the freedom in choice of basis, the precise details of grouping and splitting are not unique.\nOne speci\ufb01c choice of convention is the tensor product basis, de\ufb01ning a basis on the product space\nsimply given by the product of the respective bases. The canonical use of tensor product bases in\nquantum information allows for the grouping and splitting described above to be dealt with implicitly.\nStatements such as |0\u27e9\u2297|1\u27e9\u2261|01\u27e9omit precisely this grouping: notice that the tensor product on the\nleft is a 2 \u00d7 2 dimensional matrix, whilst the right hand-side is a 4-dimensional vector. The \u2018tensor\nproduct\u2019 used in quantum information is often in fact a Kronecker product, given by a true tensor\nproduct followed by just such a grouping.\nMore concretely, suppose we use an index convention that can be considered a higher-dimensional\ngeneralisation of column-major ordering. If we take a rank n + m tensor, and group its \ufb01rst n indices\nand last m indices together to form a matrix\nTI,J := Ti1,...,in;j1,...,jm\n(1.9)\nwhere we have de\ufb01ned our grouped indices as\nI := i1 + d(i)\n1 \u00b7 i2 + d(i)\n1 d(i)\n2 \u00b7 i3 + \u00b7 \u00b7 \u00b7 + d(i)\n1 . . . d(i)\nn\u22121 \u00b7 in,\n(1.10)\nJ := j1 + d(j)\n1\n\u00b7 j2 + d(j)\n1 d(j)\n2\n\u00b7 j3 + \u00b7 \u00b7 \u00b7 + d(j)\n1 . . . d(j)\nm\u22121 \u00b7 jm,\n(1.11)\nwhere d(i)\nx (d(j)\nx ) is the dimension of the xth index of type i(j). When such a grouping is given, we can\nnow treat this tensor as a matrix, performing standard matrix operations.\nAn important example is the singular value decomposition (SVD), given by TI,J = P\n\u03b1 UI,\u03b1S\u03b1,\u03b1 \u00afVJ,\u03b1.\nBy performing the above grouping, followed by the SVD, and then splitting the indices back out, we\nget a higher dimensional version of the SVD\nTi1,...,in;j1,...,jm =\nX\n\u03b1\nUi1,...,in,\u03b1S\u03b1,\u03b1 \u00afVj1,...,jm,\u03b1.\nSo long as we choose them to be consistent, the precise method by which we group and split is\nimmaterial in this overall operation. As a result we will keep this grouping purely implicit, as in the\n\ufb01rst equality Eq. (1.8). This will be especially useful for employing notions de\ufb01ned for matrices and\nvectors to higher rank objects, implicitly grouping then splitting. Graphically the above SVD will\nsimply be denoted\nT\nSVD\n\u2212\u2212\u2212\u2192\nU\nS\nV \u2020\n,\n(1.12)\nwhere U and V are isometric (U\u2020U = V \u2020V = 1) across the indicated partitioning, and where the\nconjugation in V \u2020 is included for consistency with conventional notation and also taken with respect\nto this partitioning. We will refer to such a partitioning of the indices in to two disjoint sets as a\nbisection of the tensor.\n6\n", "9": "Aside 1 : Why do we care so much about the singular value decomposition?\nOne of the main uses of tensor networks in quantum information is representing states\nwhich belong to small but physically relevant corners of an otherwise prohibitively large Hilbert\nspace, such as low-entanglement states. The central backbone of this idea is that of low matrix-\nrank approximations. Suppose we have some matrix, and we want the ideal low matrix-rank\napproximation thereof. Eckart and Young [1] showed that if we measure error in the Frobenius\nnorm, then trimming the singular value decomposition is an ideal approximation. Speci\ufb01cally\ntake X = USV \u2020 to be the SVD of X, then the trimmed version of X is given by\nX(k) = US(k)V \u2020\nwhere S(k) has had all but the largest k singular values set to zero (i.e. has matrix-rank k), then\nEckart-Young theorem says that\n\r\rX \u2212X(k)\r\r\nF \u2264\u2225X \u2212Y \u2225F for all Y of matrix-rank k. Mirsky\nfurther generalised this result in Ref. [2] to show optimality in all unitarily invariant norms.\nWhenever we use the term trim, we are referring to this very method of low-rank approximation.\n1.3\nTensor networks\nCombining the above tensor operations, we can now give a single de\ufb01nition of a tensor network. A\ntensor network is a diagram which tells us how to combine several tensors into a single composite\ntensor. The rank of this overall tensor is given by the number of unmatched legs in the diagram.\nThe value for a given con\ufb01guration of external indices, is given by the product of the values of the\nconstituent tensors, summed over all internal index labellings consistent with the contractions. A\ngeneric example of this is given below:\n=\nj\ni\nwhere\nj\ni\n:=\nX\n\u03b1,\u03b2,\u03b3,\u03b4\n\u03f5,\u03b6,\u03b7\nY\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3\n\u03b1\n\u03b1\n\u03b2\u03b2\n\u03b3\n\u03b3\n\u03b4 \u03b4\n\u03f5 \u03f5\n\u03b6\n\u03b6\n\u03b7\n\u03b7\ni\nj\n\uf8fc\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8fd\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8fe\n(1.13)\n1.4\nBubbling\nWhilst tensor networks are de\ufb01ned in such a way that their values are independent of the order in\nwhich the constituent tensors are contracted, such considerations do in\ufb02uence the complexity and\npracticality of such computations. Tensor networks\ncan be contracted by beginning with a single\ntensor and repeatedly contracting it against tensors one-at-a-time. The order in which tensors are\nintroduced and contracted is known as a bubbling.\nAs the bubbling is performed the network is\nswallowed into the stored tensor, until only the result remains.\nMany networks admit both e\ufb03cient and ine\ufb03cient bubblings, highlighting the need for prudence\nwhen planning out contractions. Take for example a ladder-shaped network (we\u2019ll see a few of these\nin the following lectures). One bubbling we may consider is to contract along the top of the ladder,\nthen back along the bottom. Showing both this bubbling, as well as the partially contracted tensor\nthat is kept in memory (in red), we see this bubbling looks like:\n\u2192\n\u2192\n\u2192\n\u2192\n\u2192\n(1.14)\n\u2192\n\u2192\n\u2192\n\u2192\n\u2192\n(1.15)\nThe scaling of this procedure is however quite unfavourable; consider a ladder of length n. At the\nmidpoint of this contraction, when the top has been contracted, the tensor being tracked has rank\n7\n", "10": "n, and thus the number of entries is scaling exponentially with n. As such the memory and time\nfootprints of this contraction are also exponential, rendering it infeasible for large n. If however we\ncontract each rung in turn, the tracked tensor has a rank never more than 3, giving constant memory\nand linear time costs.\n\u2192\n\u2192\n\u2192\n\u2192\n\u2192\n(1.16)\n\u2192\n\u2192\n\u2192\n\u2192\n\u2192\n(1.17)\nThe memory footprint at any step during the contraction corresponds to the product of the dimen-\nsions of each leg passing through the boundary of the contracted region (see the red legs in Eq. (1.18)).\nWhilst the above ladder arrangement possesses both good and bad bubblings, some networks possess\nan underlying graph structure that does not admit any e\ufb03cient contraction ordering. A good example\nof this is the 2D grid; due to the 2D structure of this lattice, it is clear that the contracted region must,\nsomewhere near the middle of the contracting procedure, have a perimeter on the order of \u221an where\nn is the number of tensors. As a result such contractions generically take exponential time/memory to\nperform. An example of a high cost step during such a bubbling is shown below, with the prohibitively\nlarge perimeter indicated by the red legs.\n(1.18)\nAlthough the bubblings we have depicted here involve picking a single tensor and contracting\nothers into it one-by-one, this will frequently not be the most e\ufb03cient order; often a multibubbling\napproach is faster. Ref. [3] provides code which allows for \ufb01nding optimal bubbling order for networks\nof up to 30-40 tensors. This code interfaces with that provided in Ref. [4] and Ref. [5], providing a\ncomplete tensor network package.\n1.5\nComputational Complexity\nAbove we\u2019ve described that there exist networks which stymie the speci\ufb01c contraction procedures\nwe\u2019ve outlined. In this section we\u2019ll see that there also exist networks for which there are complexity\ntheoretic obstructions which do not allow for any contraction procedure to be e\ufb03cient.\nWe will now consider the computational complexity associated with tensor network contractions.\nWhilst all of the tensor networks we will consider in later lectures constitute memory-e\ufb03cient repre-\nsentations of objects such as quantum states, not all permit e\ufb03cient manipulation. This demonstrates\nthat how one wishes to manipulate a tensor network is an important part of considering them as\nans\u00a8atze.\nWhilst algorithms which can speed up tensor network contractions by optimising the bubbling\nused [3\u20135], as discusssed above, the underlying computational problem is NP-complete [6,7]\nEven ignoring the speci\ufb01c bubbling used, the complexity of the overall contraction procedure can\nalso be shown to be prohibitive in general. Consider a network made from the binary tensors e and n.\nThe value of e is 1 if and only if all indices are identical, and zero otherwise, whilst n has value 1 if and\nonly if all legs di\ufb00er and 0 otherwise. Take an arbitrary graph, and construct a tensor network with\nan e tensor at each vertex and n tensor in the middle of each edge, with the connectedness inherited\nfrom the graph.\n8\n", "11": "\u2212\u2192\ne\ne\ne\ne\ne\ne\nn\nn\nn\nn\nn\nn\nn\n(1.19)\nBy construction, the non-zero contributions to the above tensor network correspond to an assign-\nment of index values to each vertex (enforced by e) of the original graph, such that no two neighbouring\nvertices share the same value (enforced by n). If each index is q-dimensional this is a vertex q-colouring\nof the graph, and the value of the tensor network corresponds to the number of such q-colourings.\nAs determining the existence of a q-colouring is an NP-complete problem [8], contracting this graph\nis therefore #P-complete [9]. Indeed similar constructions exist for tensor networks corresponding to\n#SAT and other #P-complete problems [10]. As we will see later in Section 6, there also exists a\nquantum hardness result which shows approximate contraction to be Post-BQP-hard, putting it inside\na class of problems not believed to be e\ufb03ciently solvable on even a quantum computer.\nProblems 1\nSolutions in accompanying document.\n1. Consider the following tensors, in which all indices are three-dimensional, indexed from 0:\nA\ni\nj\n= i2 \u22122j,\nB\ni\nj\nk\n= \u22123ij + k,\n(1.20)\nC\ni\nj\n= j\nD\ni\nj\nk\n= ijk.\n(1.21)\nCalculate the value of the following tensor network:\nA\nB\nC\nD\n(1.22)\n2. In this question we are going to consider expanding out a contraction sequence, in a manner\nwhich would be needed when coding up contractions. Given a network, and an associated\nbubbling, we wish to write out a table keeping track of the indices of the current object,\nthe tensor currently being contracted in, the indices involved in that contraction, and new\nindices left uncontracted. For example for the network\nA\nC\nB\n\u03b2\n\u03b1\n\u03b3\n\u03b4\n(1.23)\nwhere the bubbling is performed in alphabetical order, then the table in question looks like\n9\n", "12": "Current\nTensor\nContract\nNew\n\u2013\nA\n\u2013\n\u03b1, \u03b2\n\u03b1, \u03b2\nB\n\u03b1\n\u03b3\n\u03b2, \u03b3\nC\n\u03b2, \u03b3\n\u03b4\nFor the tensor network\nA\nB\nC\nD\nE\n\u03b1\n\u03b2\n\u03b3\n\u03b4\n\u03f5\n,\n(1.24)\nconstruct a corresponding table, where contraction is once again done in alphabetical order.\n3.\n(a) Calculate the contraction of the tensor network in Eq. (1.19) for bond dimension 3,\ni.e. calculate the number of three-colourings of the corresponding graph.\n(b) Using the e and n tensors from Section 1.5, come up with a construction for a tensor\nnetwork which gives the number of edge colourings. For a planar graphs, construct an\nanalogous network to count face colourings.\n(c) Using tensor networks, determine the minimum number of colours required to vertex\nand edge colour the below graph (known as the chromatic number and index respec-\ntively).\n(1.25)\n4. Much like the singular value decomposition, given a bisection of the indices we can consider\nnorms of tensors.\n(a) Does the operator norm depend on the bisection, i.e. are the operator norms across\nany two bisections of the same tensor necessarily equal?\n(b) What about the Frobenius norm? If they can di\ufb00er, give an example, if not draw a\ntensor network diagram that shows it to be manifestly independent of bisection.\n5. Write out the Einstein notation corresponding to the network in Eq. (7.1).\n1.7\nReferences\n[1] C. Eckart and G. Young, \u201cThe approximation of one matrix by another of lower rank,\u201d Psychometrika 1, (1936).\n[2] L. Mirsky, \u201cSymmetric gauge functions and unitarily invariant norms,\u201d The Quarterly Journal of Mathematics 11,\n1, 50\u201359, (1960).\n[3] R. N. C. Pfeifer, J. Haegeman, and F. Verstraete, \u201cFaster identi\ufb01cation of optimal contraction sequences for tensor\nnetworks,\u201d Physical Review E 90 033315, arXiv:1304.6112, (2014).\n[4] R. N. C. Pfeifer, G. Evenbly, S. Singh, and G. Vidal, \u201cNCON: A tensor network contractor for MATLAB,\u201d\narXiv:1402.0939v1, (2014).\n[5] G. Evenbly and R. N. C. Pfeifer, \u201cImproving the e\ufb03ciency of variational tensor network algorithms,\u201d Physical\nReview B 89 245118, arXiv:1402.0939v1, (2014).\n[6] I. Arad and Z. Landau, \u201cQuantum computation and the evaluation of tensor networks,\u201d SIAM Journal on Computing\n39 3089, arXiv:0805.0040, (2010).\n[7] L. Chi-Chung, P. Sadayappan, and R. Wenger, \u201cOn Optimizing a Class of Multi-Dimensional Loops with Reduction\nfor Parallel Execution,\u201d Parallel Processing Letters 07 157\u2013168, (1997).\n[8] M. R. Garey, D. S. Johnson, and L. Stockmeyer, \u201cSome simpli\ufb01ed NP-complete problems,\u201d in Proceedings of the\nsixth annual ACM symposium on Theory of computing - STOC \u201974, 47\u201363, ACM Press, (1974).\n10\n", "13": "[9] M. Dyer, L. A. Goldberg, C. Greenhill, and M. Jerrum, \u201cThe Relative Complexity of Approximate Counting\nProblems,\u201d Algorithmica 38 471\u2013500, (2004).\n[10] J. D. Biamonte, J. Morton, and J. Turner, \u201cTensor Network Contractions for #SAT,\u201d Journal of Statistical Physics\n160 1389\u20131404, arXiv:1405.7375, (2015).\n11\n", "14": "2\nQuantum information examples\nIn this lecture we will cover a few examples of concepts in quantum information which can be better\nunderstood in tensor network notation. This lecture won\u2019t serve as much as an introduction to these\nconcepts, but instead as a Rosetta stone for those familiar with quantum information and not with\nTNN. For a more thorough introduction to quantum information see the textbooks of Refs. [1\u20133] or\nlecture notes of Refs. [4,5]. We note that for the study of open quantum systems, a more specialised\nform of TNN was developed in Ref. [6].\n2.1\nBell state and the Bell basis\nThe Bell basis forms a convenient orthonormal set of two qubit states that exhibit maximal entangle-\nment. The standard notation for this basis is\n|\u03a6\u00b1\u27e9:=\n\u0010\n|0\u27e9\u2297|0\u27e9\u00b1 |1\u27e9\u2297|1\u27e9\n\u0011\n/\n\u221a\n2\nand\n|\u03a8\u00b1\u27e9:=\n\u0010\n|0\u27e9\u2297|1\u27e9\u00b1 |1\u27e9\u2297|0\u27e9\n\u0011\n/\n\u221a\n2.\nThe \ufb01rst of this basis, |\u03a6+\u27e9, we shall denote |\u2126\u27e9and simply refer to as the Bell state. Thought of as\na matrix, \u2126is proportional to the one qubit identity,\n|\u2126\u27e9=\n1\n\u221a\n2\n\uf8eb\n\uf8ec\n\uf8ec\n\uf8ed\n1\n0\n0\n1\n\uf8f6\n\uf8f7\n\uf8f7\n\uf8f8\nVectorise\n\u21bc\u2212\u2212\u2212\u2212\u2212\n\u2212\u2212\u2212\u2212\u2212\u21c1\nMatricise\n1\n\u221a\n2\n\u00121\n0\n0\n1\n\u0013\n= I/\n\u221a\n2.\n(2.1)\nIn tensor network notation, this is represented simply as a line connecting its two legs.\n\u2126\n=\n1\n\u221a\n2\n(2.2)\nNext we will de\ufb01ne \u2126(O) to be the vectorisation of an operator O, such that |\u2126(O)\u27e9= (O \u2297I)|\u2126\u27e9.\n\u2126(O)\n=\n1\n\u221a\n2\nO\n(2.3)\nGiven this de\ufb01nition, we can see that the Bell basis simply corresponds to a vectorisation of the\nPauli operators\n|\u03a6+\u27e9= |\u2126(I)\u27e9,\n|\u03a6\u2212\u27e9= |\u2126(Z)\u27e9,\n|\u03a8+\u27e9= |\u2126(X)\u27e9,\n|\u03a8\u2212\u27e9\u221d|\u2126(Y )\u27e9.\nThus we see that the Bell basis is intimately linked to the Pauli operators, with the Euclidean inner\nproduct on Bell basis states corresponding to the Hilbert-Schmidt inner product on Paulis.\n2.2\nQuantum Teleportation\nGiven this notation for the Bell basis, we can now understand Quantum Teleportation in TNN. The\nidea here is for two parties (Alice and Bob, say) to share a Bell state. Given this shared resource of\nentanglement, we then allow Alice to perform local operations on her half of the pair, and an arbitrary\n\ufb01ducial qubit. After transmitting only two classical bits, Bob can then correct his half of the pair such\nthat he recovers the state of the original \ufb01ducial qubit, successfully teleporting the data within.\nThe procedure for teleportation goes as follows. First Alice performs a projective measurement\nin the Bell basis on both the \ufb01ducial qubit and her Bell qubit, receiving outcome |\u2126(p)\u27e9. The result\nof this measurement is then (classically) transmitted to Bob, requiring two communication bits. Bob\nthen performs the corresponding Pauli p on his Bell qubit, correcting the in\ufb02uence of the measurement.\nTaking the \ufb01ducial state to be |\u03c8\u27e9, and supposing the measurement outcome corresponds to |\u2126(p)\u27e9,\nthen this procedure gives Bob a \ufb01nal state of |\u03c6\u27e9= |\u03c8\u27e9/2:\n12\n", "15": "|\u03c6\u27e9=\nCorrection\nz }| {\n\u0010\npB\n\u0011\nTeleportation\nz\n}|\n{\n\u0010\n\u27e8\u2126A1A2(p)|\n\u0011\nSetup\nz\n}|\n{\n\u0010\n|\u03c8A1\u27e9\u2297|\u2126A2B\u27e9\n\u0011\n= |\u03c8\u27e9/2\n(2.4)\nwhere A1 and A2 correspond to the single qubit registers of Alice, and B to Bob\u2019s qubit. In tensor\nnetwork notation this can be clearly seen:\n|\u03c6\u27e9=\n\u03c8\n1\n\u221a\n2\n1\n\u221a\n2\np\u2020\np\nBob\nAlice\n(2.5)\n= 1\n2\n\u03c8\np\u2020\np\n(2.6)\n= |\u03c8\u27e9/2\n(2.7)\nwhere the dashed line indicates the physical separation of the two parties.\nAs such we can see that |\u03c8\u27e9is correctly transmitted for any measurement outcome p, each of which\nis seen with probability 1/4. Thus we see that in spite of the non-deterministic intermediary states,\nthe overall procedure is deterministic. Analogous procedures can work for p being elements of any\nset of operators which are orthonormal with respect to the Hilbert-Schmidt inner product, e.g. higher\ndimensional Paulis.\n2.2.1\nGate Teleportation\nThe idea behind gate teleportation is similar to regular teleportation, but utilises a general maximally\nentangled state instead of the Bell state speci\ufb01cally. Suppose we prepare a maximally entangled state\n|\u2126(UT )\u27e9corresponding to a unitary U, and post select on a Bell basis measurement of |\u2126(p)\u27e9, followed\nby a correcting unitary Cp, then Bob ends up with the state:\n|\u03c6\u27e9=\nCorrection\nz }| {\n\u0010\nCp\n\u0011\nTeleportation\nz\n}|\n{\n\u0010\n\u27e8\u2126A1A2(p)|\n\u0011\nSetup\nz\n}|\n{\n\u0010\n|\u03c8A1\u27e9\u2297|\u2126A2B\n\u0000UT )\u27e9\n\u0011\n(2.8)\n=\n\u03c8\nUT\n1\n\u221a\n2\n1\n\u221a\n2\nAlice\nBob\np\u2020\nCp\n(2.9)\n= 1\n2\n\u03c8\np\u2020\nU\nCp\n(2.10)\n= CpUp\u2020|\u03c8\u27e9/2\n(2.11)\nIf we take Cp := UpU\u2020 then Bob receives U|\u03c8\u27e9for all measurement outcomes, i.e. |\u03c6\u27e9\u221dU|\u03c8\u27e9.\nIf U is a Cli\ufb00ord operator2, this correction is also a Pauli, making the procedure no more resource\nintensive in terms of the gates used than standard teleportation.\nAn example of where this is useful is in the case where Paulis can be reliably performed, but\nCli\ufb00ords can only be applied non-deterministically. Gate teleportation allows us to prepare the |UT \u27e9\n\ufb01rst, simply retrying the non-deterministic procedure until it succeeds. Once this has succeeded, we\ncan use gate teleportation to apply this unitary on the data state using only Pauli operations. As\nsuch we can avoid needing to apply non-deterministic gates directly on our target state, endangering\nthe data stored within.\n2The Cli\ufb00ords are the group of unitaries which map Paulis to Paulis under conjugation.\n13\n", "16": "2.3\nPuri\ufb01cation\nFor a given mixed state \u03c1, a puri\ufb01cation is a pure state |\u03c8\u27e9which is extended into a larger system (the\nadded subsystem is known as the puri\ufb01cation system), such that the reduced density on the original\nsystem is \u03c1. One such puri\ufb01cation is given by |\u03c8\u27e9\u221d(\u221a\u03c1 \u2297I)|\u2126\u27e9= |\u2126(\u221a\u03c1)\u27e9, which can be simply seen\nby considering the corresponding tensor networks. The de\ufb01nition of the state is\n\u03c8\n=\n\u221a\u03c1\n(2.12)\nwhich gives a reduced density of\nTr2\n\u0010\n|\u03c8\u27e9\u27e8\u03c8|\n\u0011\n=\n\u03c8\n\u03c8\n=\n\u221a\u03c1\n\u221a\u03c1\n=\n\u03c1\n(2.13)\nBy dimension counting, it can be shown that the above puri\ufb01cation is unique up to an isometric\nfreedom on the puri\ufb01cation system, i.e. all puri\ufb01cations are of the form\n\u0000\u221a\u03c1 \u2297U\n\u0001\n|\u2126\u27e9where U\u2020U = 1.\nEquivalently all puri\ufb01cations can be considered to be proportional to (\u221a\u03c1 \u2297I)|\u2126\u27e9, where |\u2126\u27e9is some\nmaximally entangled state other than the Bell state.\n2.4\nStinespring\u2019s Dilation Theorem\nStinespring\u2019s Theorem says that any quantum channel E \u2013 a completely positive trace preserving\n(CPTP) map \u2013 can be expressed as a unitary map V acting on a larger system followed by a partial\ntrace, i.e.\nE(\u03c1) = Tr1\nh\nV \u2020 (\u03c1 \u2297|0\u27e9\u27e80|) V\ni\n.\n(2.14)\nPhysically this means that dynamics of an open system is equivalent to those of a subsystem of a\nlarger, closed system \u2014 the founding tennet of the Church of the Larger Hilbert Space. Any CPTP\nmap can be represented by a set of Kraus operators Ki such that\nE(\u03c1) =\nX\ni\nK\u2020\ni \u03c1Ki where\nX\ni\nKiK\u2020\ni = I.\n(2.15)\nIn TNN this looks like\n\u03c1\nE\n=\n\u03c1\nK\u2020\nK\nwhere\nK\u2020\nK\n=\n(2.16)\nwhere the transposition in the Hermitian conjugate is done with respect to the horizontal legs, and\nthe upper leg corresponds to the virtual index i.\nNext we de\ufb01ne the tensor U as\nU\n:=\nK\u2020\n(2.17)\nwhere we can see that U is an isometry (U\u2020U = I), which we can think of as a unitary V with an\nomitted ancilla\nU\n=\nV\n|0\u27e9.\n(2.18)\n14\n", "17": "Using this, and partial tracing over the upper index, we get the Stinespring Dilation Theorem as\ndesired:\nE(\u03c1) =\nX\ni\nK\u2020\ni \u03c1Ki =\n\u03c1\nK\u2020\nK\n(2.19)\n=\n\u03c1\nK\u2020\nK\n(2.20)\n=\n\u03c1\nU\nU\u2020\n(2.21)\n=\n\u03c1\n|0\u27e9\u27e80|\nV\nV \u2020\n(2.22)\n= Tr1\nh\nV \u2020 (\u03c1 \u2297|0\u27e9\u27e80|) V\ni\n(2.23)\nProblems 2\nSolutions in accompanying document.\n1. Consider the inverse of teleportation. Alice wishes to send classical bits to Bob, and pos-\nsesses a quantum channel through which she can send Bob qubits.\nHow many bits of\ninformation can be communicated in a single qubit? For simplicity consider the case where\nBob can only perform projective measurements.\n2. Suppose Alice and Bob initially shared a Bell pair. Does this pre-shared entanglement\nresource boost the amount of classical information that can be successfully communicated,\nand if so by how much? Hint: Notice that the four possible Bell states di\ufb00er by a Pauli\nacting on a single qubit.\n2.6\nReferences\n[1] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information 10th Anniversary Edition,\nCambridge University Press, (2011).\n[2] N.\nD.\nMermin,\nQuantum\nComputer\nScience:\nAn\nIntroduction,\nCambridge\nUniversity\nPress,\n(2007),\nhttp://www.lassp.cornell.edu/mermin/qcomp/CS483.html.\n[3] M. M. Wilde, Quantum Information Theory, Cambridge University Press, arXiv:1106.1445 (2013).\n[4] J. Preskill, Quantum Computation, http://www.theory.caltech.edu/people/preskill/ph229/.\n[5] J. Watrous, Theory of Quantum Information and Introduction to Quantum Computing, https://cs.uwaterloo.ca/ wa-\ntrous/LectureNotes.html.\n[6] C. J. Wood, J. D. Biamonte, and D. G. Cory, \u201cTensor networks and graphical calculus for open quantum systems,\u201d\nQuantum Information and Computation 15, 0759, arXiv:1111.6950, (2011).\n15\n", "18": "3\nMatrix Product States\nNow that we have established the notation, the remaining lectures will examine some key tensor\nnetworks and algorithms for strongly interacting quantum many body systems. We begin with one\ndimensional models.\nMatrix product states (MPS) are a natural choice for e\ufb03cient representation of 1D quantum low\nenergy states of physically realistic systems [1\u20136]. This lecture will begin by motivating and de\ufb01ning\nMPS in two slightly di\ufb00erent ways. We will then give some analytic examples of MPS, demonstrating\nsome of the complexity which can be captured with this simple network. Some simple properties of\nMPS will then be explained, followed by a generalisation of the network to operators rather than pure\nstates.\nLet |\u03c8\u27e9= Pd\u22121\nj1j2...jN=0 Cj1j2...jN |j1\u27e9\u2297|j2\u27e9\u2297\u00b7 \u00b7 \u00b7 \u2297|jN\u27e9be the (completely general) state of N qudits\n(d dimensional quantum system). The state is completely speci\ufb01ed by knowledge of the rank-N tensor\nC.\nBy splitting the \ufb01rst index out from the rest, and performing an SVD, we get the Schmidt decom-\nposition\n|\u03c8\u27e9=\nX\ni\n\u03bbi|Li\u27e9\u2297|Ri\u27e9,\n(3.1)\nwhere \u03bbi are the Schmidt weights and {|Li\u27e9} and {|Ri\u27e9} are orthonormal sets of vectors. Graphically\nthis looks like\n\u03c8\n=\nR\n\u03bb\nL\n,\n(3.2)\nwhere \u03bb is a diagonal matrix containing the Schmidt weights.\nThe \u03b1-R\u00b4enyi entropy is given by\nS\u03b1(\u03c1) =\n1\n1 \u2212\u03b1 log Tr \u03c1\u03b1,\n(3.3)\nwhere \u03c1 is some density matrix. Note that the entanglement rank S0 is simply the (log of the) number\nof nonzero Schmidt weights and the von Neumann entropy is recovered for \u03b1 \u21921. We also note that\nthe Schmidt weights now correspond precisely to the singular values of the decomposition Eq. (3.2),\nand so these values capture the entanglement structure along this cut.\nWe can now perform successive singular value decompositions along each cut in turn, splitting out\nthe tensor into local tensors M, and diagonal matrices of singular values \u03bb quantifying the entangle-\nment across that cut.\n\u03c8\n=\nR(1)\n\u03bb(1)\nM(1)\n(3.4)\n=\nR(2)\n\u03bb(1)\n\u03bb(2)\nM(1)\nM(2)\n(3.5)\n=\nM(3)\n\u03bb(1)\n\u03bb(2)\n\u03bb(3)\nM(1)\nM(2)\nM(4)\n(3.6)\nBy now contracting3 the singular values tensors \u03bb(i) into the local tensors M(i) we get the more generic\nform\n|\u03c8\u27e9=\nA(1)\nA(2)\nA(3)\nA(4)\n.\n(3.7)\n3Into precisely which tensor the singular values are contracted can be important, and relates to gauge \ufb01xing the MPS,\nsee Section 3.3.2.\n16\n", "19": "This is the matrix product state. It is not yet clear that we have done anything useful. The above\nconstruction is both general and exact, so we have the same number of coe\ufb03cients in an arguably\nmuch more complicated form.\nSuppose however we consider states for which the entanglement rank across any bisection of the\nchain is bounded. In particular, suppose that only D of the Schmidt weights were non-zero. Then\nwe can use the MPS form to take advantage of this by truncating the \u03bb matrix to make use of\nthis property.\nIn particular, any state with a so-called strong area law such that S0 \u2264log c for\nsome constant c along any bipartition can be expressed (exactly) using an MPS with only O(dNc2)\ncoe\ufb03cients. As discussed in Sec. 5, there are many relevant states for which an area law for the von\nNeumann entropy (S1 = O(1)) is su\ufb03cient to guarantee arbitrarily good approximation with an MPS\nof only poly(N) bond dimension [1\u20133].\nIn TNN, the name matrix product state is a misnomer, as most tensors involved are in fact rank-3.\nThe uncontracted index is referred to as the physical index, whilst the other two are virtual, bond or\nmatrix indices. For reasons of convenience, as well as to capture periodic states most e\ufb03ciently, the\nMPS ansatz is usually modi\ufb01ed from Eq. (3.7) to\n\f\f\f\u03c8\nh\nA(1), A(2), . . . , A(N)iE\n=\nX\ni1i2...iN\nTr\nh\nA(1)\ni1 A(2)\ni2 . . . A(N)\niN\ni\n|i1i2 . . . iN\u27e9,\n(3.8)\nor in the translationally invariant case\n|\u03c8[A]\u27e9=\nX\ni1i2...iN\nTr [Ai1Ai2 . . . AiN ] |i1i2 . . . iN\u27e9.\n(3.9)\nNote that in this form the matrix indices are suppressed and matrix multiplication is implied. The\ngraphical form of this MPS is\n|\u03c8[A]\u27e9=\n.\n(3.10)\n3.1\n1D Projected Entangled Pair States\nIn addition to the above construction, MPS can (equivalently) be viewed as a special case of the\nprojected entangled pair states (PEPS) construction [2, 7, 8]. This proceeds by laying out entangled\npair states |\u03c6\u27e9on some lattice and applying some linear map P between pairs\n|\u03c8\u27e9=\nP\nP\nP\nP\nP\nP\nP\nP\nP\n,\n(3.11)\nwhere\n|\u03c6\u27e9=\n(3.12)\nis the chosen entangled pair. In Lecture 6, we will generalise this construction to arbitrary dimensions\nand arbitrary lattices.\nIt is clear that this construction is equivalent to the tensor network construction by letting |\u03c6\u27e9=\nPd\u22121\nj=0 |dd\u27e9. We can write the linear map P as\nP =\nX\ni,\u03b1,\u03b2\nAi;\u03b1,\u03b2|i\u27e9\u27e8\u03b1\u03b2|.\n(3.13)\nThe tensor A is exactly the MPS tensor introduced above, and the choice of entangled pair ensures\nthat the A tensor corresponding to a pair of PEPS \u2018projectors\u2019 applied to the Bell state above is\nexactly the contraction of the corresponding A tensors:\nP(1) \u2297P(2)|\u03c6\u27e92,3 =\nX\ni1,i2;\u03b11,\u03b21,\u03b12,\u03b22,j\nA(1)\ni1;\u03b11,\u03b21A(2)\ni2;\u03b12,\u03b22|i1i2\u27e9\u27e8\u03b11\u03b21\u03b12\u03b22|(1 \u2297|jj\u27e9\u22971)\n(3.14)\n17\n", "20": "=\nX\ni1,i2;\u03b11,\u03b21,\u03b22\nA(1)\ni1;\u03b11,\u03b21A(2)\ni2;\u03b21,\u03b22|i1i2\u27e9\u27e8\u03b11\u03b22|.\n(3.15)\nThus, we see that the two descriptions are equivalent, and interchanged through the applications\nof local unitaries to the virtual indices of A or equivalently changing the maximally entangled pair in\nthe PEPS.\nWe note that this should not generally be seen as a practical preparation procedure. Generically\nthe PEPS tensors will map states down into a non-trivial subspace, with the physical implementation\nof this requiring post-selected measurements. If one of these fails, we need to go back and begin the\nconstruction from the start, meaning this procedure is not generally scalable.\n3.2\nSome MPS states\nProduct State\nLet\nA0 =\n\u00001\n\u0001\n,\nA1 =\n\u00000\n\u0001\n.\n(3.16)\nThis gives the state |00 . . . 0\u27e9, as does\nA0 =\n\u00121\n0\n0\n0\n\u0013\n,\nA1 =\n\u00120\n0\n0\n0\n\u0013\n.\n(3.17)\nW State\nWhat state do we get when we set\nA0 =\n\u00121\n0\n0\n1\n\u0013\n,\nA1 =\n\u00120\n1\n0\n0\n\u0013\n,\n(3.18)\nand we choose the boundary conditions of the MPS to be\n|\u03c8[A]\u27e9=\nX\n?\n(3.19)\nWe have A0A0 = A0, A0A1 = A1, A2\n1 = 0 and Tr[A1X] = 1, so we get\n|W\u27e9=\nN\nX\nj=1\n|000 . . . 01j000 . . . 0\u27e9,\n(3.20)\nthe W-state [2].\nGHZ State\nIf we choose |\u03c6\u27e9= |00\u27e9+ |11\u27e9and P = |0\u27e9\u27e800| + |1\u27e9\u27e811|, or the equivalent MPS tensor\nA0 =\n\u00121\n0\n0\n0\n\u0013\n,\nA1 =\n\u00120\n0\n0\n1\n\u0013\n,\n(3.21)\nthen we get the Greenberger-Horne-Zeilinger (GHZ) state [2]\n|GHZ\u27e9= |00 . . . 0\u27e9+ |11 . . . 1\u27e9.\n(3.22)\n18\n", "21": "AKLT State\nSuppose we wish to construct an SO(3) symmetric spin-1 state [5,6,9]. Let |\u03c6\u27e9= |01\u27e9\u2212|10\u27e9be the\nSO(3) invariant singlet state. Let P : C2\u00d72 \u2192C3 be the projector onto the spin-1 subspace\nP = |\u02dc1\u27e9\u27e800| + |\u02dc0\u27e9\u27e801| + \u27e810|\n\u221a\n2\n+ |\u2212\u02dc1\u27e9\u27e811|.\n(3.23)\nThe advantage is that the spin operators on the corresponding systems pull through P, meaning it\ncommutes with rotations. Let (Sx, Sy, Sz) be the spin vector on the spin-1 particle, and (Xi, Yi, Zi)/2\nthe spin vector on the ith qubit, then this means:\nSZP =\n\u0000|\u02dc1\u27e9\u27e8\u02dc1| \u2212|\u2212\u02dc1\u27e9\u27e8\u2212\u02dc1|\n\u0001 \u0012\n|\u02dc1\u27e9\u27e800| + |\u02dc0\u27e9\u27e801| + \u27e810|\n\u221a\n2\n+ |\u2212\u02dc1\u27e9\u27e811|\n\u0013\n(3.24)\n= |\u02dc1\u27e9\u27e800| \u2212|\u2212\u02dc1\u27e9\u27e811|\n(3.25)\n= P Z1 + Z2\n2\n(3.26)\nSXP = |\u02dc0\u27e9\n\u0000\u27e8\u02dc1| + \u27e8\u2212\u02dc1|\n\u0001\n+\n\u0000|\u02dc1\u27e9+ |\u2212\u02dc1\u27e9\n\u0001\n\u27e8\u02dc0|\n\u221a\n2\n\u0012\n|\u02dc1\u27e9\u27e800| + |\u02dc0\u27e9\u27e801| + \u27e810|\n\u221a\n2\n+ |\u2212\u02dc1\u27e9\u27e811|\n\u0013\n(3.27)\n=\n \n|\u02dc0\u27e9(\u27e800| + \u27e811|)\n\u221a\n2\n+\n\u0000|\u02dc1\u27e9+ |\u2212\u02dc1\u27e9\n\u0001\n(\u27e801| + \u27e810|)\n2\n!\n(3.28)\n= P X1 + X2\n2\n,\n(3.29)\nwith the same holding for SY . Thus the state obtained after this projection is fully SO(3) symmetric,\nbut has a nontrivial entanglement structure (which would not be obtained if the state was simply a\nsinglet at each site for example).\nThis state has many interesting properties. We can write a 2-local Hamiltonian for which this is\nthe ground state. Let \u03a02 be the projector onto the spin-2 subspace of a pair of spin-1 particles. This\noperator has eigenvalues {0, 1}. \u03a02 annihilates an adjacent pair of spin-1 particles, since they are built\nfrom two spin-1/2s and a spin-0, so have no overlap with the spin-2 subspace. It is simple to check\nthat on periodic boundary conditions the ground state of H = P \u03a02 is unique (and gapped).\nIf we examine the action of rotations about the three axes of the spin-1, we see that\nR\u02c6n(\u03b8)P = PR\u02c6n(\u03b8) \u2297R\u02c6n(\u03b8).\n(3.30)\nIn particular, R\u02c6x(\u03c0) 7\u2192\u2212XX, R\u02c6y(\u03c0) 7\u2192\u2212Y Y , R\u02c6z(\u03c0) 7\u2192\u2212ZZ. In Sec. 4 we will see that this tells\nus the AKLT state is in a nontrivial symmetry protected topological (SPT) phase.\nCluster State\nIt is convenient to write a bond dimension 2 MPS for this state where a physical site contains a pair\nof spins. Let\nA00 =\n\u00121\n0\n1\n0\n\u0013\nA01 =\n\u00120\n1\n0\n1\n\u0013\nA10 =\n\u0012 1\n0\n\u22121\n0\n\u0013\nA11 =\n\u00120\n\u22121\n0\n1\n\u0013\n,\n(3.31)\nor equivalently the map from virtual to physical spin-1/2 particles\nP =\n\uf8eb\n\uf8ec\n\uf8ec\n\uf8ed\n1\n0\n1\n0\n0\n1\n0\n1\n1\n0\n\u22121\n0\n0\n\u22121\n0\n1\n\uf8f6\n\uf8f7\n\uf8f7\n\uf8f8,\n(3.32)\nwhere the entangled pairs are in the Bell state |\u03c6\u27e9= |00\u27e9+|11\u27e9. The map P corresponds to the circuit\n19\n", "22": "H\n(3.33)\nNotice in this case our PEPS tensor P simply corresponds to unitary circuit. As such this is one of the\nexceptional cases in which the PEPS description can be considered a scalable preparation procedure.\nGiven an explicit MPS description of this state, we can now back out a Hamiltonian for which it\nis a ground state, allowing us to infer certain properties.\nThe initial state is constructed from entangled pairs Q |\u03c6\u27e92j,2j+1, and is the unique ground state\nof the Hamiltonian\nH = \u2212\nX\nj\n(X2jX2j+1 + Z2jZ2j+1) .\n(3.34)\nApplying the circuit (between Bell pairs with \ufb01rst qubit odd and second even), we see that this\ntransforms to\nH\u2032 = \u2212\nX\nj\n(Z2j\u22121X2jZ2j+1 + Z2jX2j+1Z2j+2)\n(3.35)\n= \u2212\nX\nk\nZk\u22121XkZk+1.\n(3.36)\nThis is precisely the cluster state Hamiltonian. The physical symmetry of this model is Z2 \u00d7 Z2,\nwhere S1 = Q\nj X2j\u22121 and S2 = Q\nj X2j. Pushing this backwards through the circuit, we see that it is\nequivalent to act on the virtual spins with S1 = Q\nj Z2jZ2j+1 and S2 = Q\nj X2jX2j+1.\nThis action tells us that, just like the AKLT state, the cluster state possesses SPT order.\n3.3\nMPS Properties\nMPS form a vanishingly small corner of the full Hilbert space, and thus we cannot hope to use them\nto approximate arbitrary states. If physically relevant states correspond to those which can be well\napproximated by MPS, and MPS manifest the same non-generic properties as these physical states,\nthen they represent an extremely useful tool to study these systems.\n3.3.1\nDecay of Correlations\nWe have already seen that MPS have bounded levels of entanglement, manifesting as strict area laws.\nWe will now investigate the type of correlations which can be represented. Let O be some operator\nfor which we wish to compute the two point correlator\n\u27e8\u03c8[A]|O0Oj+1|\u03c8[A]\u27e9,\n(3.37)\nwhere the subscript denotes the site at which the operator O is applied. Graphically this expectation\nvalue is written as:\n. . .\n. . .\n(3.38)\nWe refer to the object\nEO =\nd\u22121\nX\ni,j=0\nOi,jAi \u2297\u00afAj =\nO\n(3.39)\n20\n", "23": "as the O-transfer matrix. Note that we usually just refer to E1 as the transfer matrix and simply\ndenote it E.\nThe correlator (in the thermodynamic limit) can then be written as\n\u27e8\u03c8[A]|O0Oj+1|\u03c8[A]\u27e9= Tr\n\u0000E\u221eEO0EjEOj+1E\u221e\u0001\n(3.40)\n\u221dV \u2020\nLEjVR.\n(3.41)\nwhere VL and VR are the dominant left and right eigenvectors of E respectively. The only change\nrequired when calculating longer range correlators is inserting higher powers of E in Eq. (3.41). The\ndecay of correlators is therefore controlled by the eigenvalues of E. We can normalise A so that the\ndominant eigenvalue of E is 1, with the rest lying inside the unit disk. Thus any correlator can either\ndecay exponentially with distance or be constant. Thus we see that MPS can only capture states with\nexponentially decaying correlations [6].\n3.3.2\nGauge Freedom\nNot all MPS represent di\ufb00erent physical states [2]. The set of transformations of the description (i.e.\nthe MPS) which leaves the physical state invariant are known as gauge transformations. In the case\nof MPS, these correspond to basis transformations on the virtual level:\n|\u03c8[A]\u27e9=\nM\u22121\nM\nM\u22121\nM\nM\u22121\nM\nM\u22121\nM\nM\u22121\nM\nM\u22121\nM\n(3.42)\n=\nB\nB\nB\nB\nB\nB\n(3.43)\n= |\u03c8[B]\u27e9,\n(3.44)\nwhere Bj = MAjM\u22121. Note that M is only required to have a left inverse, so can be rectangular and\nenlarge the bond dimension.\nAnother freedom is blocking. We can combine several MPS tensors Ai1, Ai2, . . . , Aij into a single\ne\ufb00ective tensor Bk, on a larger physical region\nA number of canonical forms exist which partially gauge \ufb01x the MPS description. One of the most\ncommon is the left-isometric or left-canonical form (with right-isometric or right-canonical de\ufb01ned\nanalogously). Here the MPS tensors obey\nd\u22121\nX\nj=0\nA\u2020\njAj = 1D\u00d7D,\n(3.45)\n=\n.\n(3.46)\nThis is most useful on open boundary systems where a simple algorithm exists to put any MPS\ninto this form. It is frequently used in numerical applications, in particular when using variational\nminimisation to optimise an MPS description of a ground state (DMRG), a mixed left/right isometric\nform is used.\nPutting an MPS into this form is a partial gauge \ufb01xing.\nThe remaining freedom is that of a\nunitary4 on the virtual level, rather than general invertible matrix. This technique is heavily used in\ntensor network algorithms as a method of increasing numerical stability.\n4If you include the ability to expand the bond dimension then this grows to an isometric freedom.\n21\n", "24": "3.4\nRenormalising Matrix Product States\nWhen we renormalise a system, we usually think about attempting to write down an e\ufb00ective model at\na longer length scale which captures the low energy portion of the original model. This can be achieved\nby blocking sites together, then discarding degrees of freedom to ensure the description remains useful.\nIn the MPS, blocking can be achieved by simply contracting tensors together. How to discard only\nhigh energy degrees of freedom is a challenging question. MPS allows us to avoid having to answer\nthis question all together [10].\nSince we care only about expectation values of operators, we can work entirely in the transfer\nmatrix picture. Blocking sites together simply consists of taking products of transfer matrices\n\u02dcE = EEEEE . . . E,\n(3.47)\nwith sandwiched operators EO being renormalised similarly. Note that the dimension of \u02dcE remains D4\nat all times, so we never need to worry about discarding degrees of freedom. We can also use transfer\nmatrices formed from di\ufb00erent MPS to get o\ufb00-diagonal terms of the form \u27e8\u03c8|O|\u03c6\u27e9.\n3.5\nMixed States and Many Body Operators\nAs described above, an MPS can be used to represent a pure state. How is a mixed state represented\nin this language?\nLet |\u03c8[A]\u27e9be some (pure) MPS state. We can write the density matrix corresponding to |\u03c8[A]\u27e9as\n\u03c1[A] = |\u03c8[A]\u27e9\u27e8\u03c8[A]|\n(3.48)\n= \u00b7 \u00b7 \u00b7\n\u00b7 \u00b7 \u00b7 .\n(3.49)\nThe reduced density matrix on some subset of spins R will therefore be represented as\n\u03c1[A]R = |\u03c8[A]\u27e9\u27e8\u03c8[A]|\n(3.50)\n=\n,\n(3.51)\nwhere we have used the left and right normal forms to bring in the boundary terms.\nThe above network is an example of what is referred to as matrix product operators (MPOs)\n[5,11,12]. The general form of MPOs we will be considering is\nvL\nvR\nM\nM\nM\nM\nM\nM\n.\n(3.52)\nIn addition to being used to represent density matrices, MPOs can be used to represent a large class of\nmany body operators, including small depth quantum circuits and local Hamiltonians. For example,\nthe transverse \ufb01eld Ising Hamiltonian\nH = \u2212J\nX\nXjXj+1 \u2212h\nX\nZj\n(3.53)\ncan be represented on a line with the (operator valued) matrix\nM =\n\uf8eb\n\uf8ed\n1\n0\n0\nX\n0\n0\n\u2212hZ\n\u2212JX\n1\n\uf8f6\n\uf8f8\n(3.54)\n22\n", "25": "and end vectors\nvL =\n\u00000\n0\n1\n\u0001\nand\nvR =\n\uf8eb\n\uf8ed\n1\n0\n0\n\uf8f6\n\uf8f8.\n(3.55)\nThe Hamiltonian on N sites is then obtained as\nH = vLMNvR.\n(3.56)\nThe Heisenberg model\nH = \u2212JX\nX\nXjXj+1 \u2212JY\nX\nYjYj+1 \u2212JZ\nX\nZjZj+1 \u2212h\nX\nZj\n(3.57)\ncan be obtained in the same fashion with\nvL =\n\u00000\n0\n0\n0\n1\n\u0001\n,\nM =\n\uf8eb\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ed\n1\n0\n0\n0\n0\nX\n0\n0\n0\n0\nY\n0\n0\n0\n0\nZ\n0\n0\n0\n0\n\u2212hZ\n\u2212JXX\n\u2212JY Y\n\u2212JZZ\n1\n\uf8f6\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f8\n,\nvR =\n\uf8eb\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ed\n1\n0\n0\n0\n0\n\uf8f6\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f8\n.\n(3.58)\nMore generally, an MPO can be used to represent any operator which does not increase the\nSchmidt rank of any state too much. An existing explicit analytic construction of MPOs for 1D local\nHamiltonians, as well as a new generalisation for higher dimensional Hamiltonians, is covered in more\ndetail in Appendix A.\nProblems 3\nSolutions in accompanying document.\n1. Describe the state given by an MPS with tensor\nA =\n0\n1\n\uf8eb\n\uf8ec\n\uf8ed\n\uf8f6\n\uf8f7\n\uf8f8\n00\n1\n0\n10\n0\n1\n01\n1/2\n\u22121/2\n11\n1/2\n\u22121/2\n1\n2\n3\nA\n,\n(3.59)\nwhere index ordering is as shown and indices 1 and 2 are combined. Boundary conditions\nrequire inserting a Pauli Z before closing periodic BCs, similar to Eq. (3.19).\n2. Describe the state given by the MPS whose only nonzero components are\n0\n0\n0\nA\n=\n1\n0\n1\nA\n=\n0\n1\n1\nA\n=\n1\n1\n0\nA\n= 1,\n(3.60)\nwhere the left and right boundary conditions are |0\u27e9.\nHint: Writing out the matrices corresponding to \ufb01xing the physical index might help!\n3. Describe the qudit state given by the MPS\ni\nj\ni \u2295j\nA\n= 1\n(3.61)\n23\n", "26": "where i, j \u2208Zd, \u2295denotes addition mod d, the left boundary condition is |0\u27e9, and the right\nboundary is |q\u27e9for some q \u2208Zd.\n4. Let G be some group. Describe the operator given by the MPO with\ng\nh\nh\ng \u00b7 h\nM\n= 1\n(3.62)\nwhere the left boundary condition is |1\u27e9, the right boundary is |q\u27e9for some q \u2208G, and g \u00b7 h\ndenotes group multiplication.\n5. Suppose the local basis is labelled by particle number. What is the action of the following\noperator (bond dimension linearly increasing left to right)?\nn\nm\nm\nn + m\nM\n= 1\n(3.63)\nwith left vector L = |0\u27e9and right vector R = PN\ni=0 i|i\u27e9.\n6. Write an MPO for the transverse-\ufb01eld-cluster Hamiltonian\nH = \u2212J\nX\nj\nZj\u22121XjZj+1 \u2212h\nX\nj\nXj.\n(3.64)\nHint: This can be done with bond dimension 4.\n7. Use the ideas of MPSs and MPOs to prove that log depth quantum circuits can be simulated\ne\ufb03ciently on a classical computer.\n3.7\nReferences\n[1] F. Verstraete and J. Cirac, \u201cMatrix product states represent ground states faithfully,\u201d Physical Review B 73, 94423,\narXiv:cond-mat/0505140v6, (2006).\n[2] D. Perez-Garcia, F. Verstraete, M. M. Wolf, and J. I. Cirac, \u201cMatrix Product State Representations,\u201d Quantum\nInformation & Computation 7, 401\u2013430, arXiv:quant-ph/0608197, (2007).\n[3] M. B. Hastings, \u201cAn area law for one-dimensional quantum systems,\u201d Journal of Statistical Mechanics 2007, P08024,\narXiv:0705.2024, (2007).\n[4] X. Chen, Z. C. Gu, and X. G. Wen, \u201cLocal unitary transformation, long-range quantum entanglement, wave function\nrenormalization, and topological order,\u201d Physical Review B 82, 155138, arXiv:1004.3835, (2010).\n[5] U. Schollw\u00a8ock, \u201cThe density-matrix renormalization group in the age of matrix product states,\u201d Annals of Physics\n326, 96\u2013192, arXiv:1008.3477, (2011).\n[6] R. Or\u00b4us, \u201cA practical introduction to tensor networks: Matrix product states and projected entangled pair states,\u201d\nAnnals of Physics 349, 117\u2013158, arXiv:1306.2164, (2014).\n[7] F. Verstraete, V. Murg, and J. Cirac, \u201cMatrix product states, projected entangled pair states, and variational\nrenormalization group methods for quantum spin systems,\u201d Advances in Physics 57, 143\u2013224, arXiv:0907.2796,\n(2008).\n[8] N. Schuch, D. P\u00b4erez-Garc\u00b4\u0131a, and I. Cirac, \u201cClassifying quantum phases using matrix product states and projected\nentangled pair states,\u201d Physical Review B 84, 165139, arXiv:1010.3732, (2011).\n[9] I. A\ufb04eck, T. Kennedy, E. H. Lieb, and H. Tasaki, \u201cRigorous results on valence-bond ground states in antiferromag-\nnets,\u201d Physical Review Letters 59, 799, (1987).\n[10] F. Verstraete, J. Cirac, J. Latorre, E. Rico, and M. Wolf, \u201cRenormalization-Group Transformations on Quantum\nStates,\u201d Physical Review Letters 94, 140601, arXiv:quant-ph/0410227, (2005).\n[11] B. Pirvu, V. Murg, J. I. Cirac, and F. Verstraete, \u201cMatrix product operator representations,\u201d New Journal of\nPhysics 12, 025012, arXiv:0804.3976, (2010).\n24\n", "27": "[12] I. P. McCulloch, \u201cFrom density-matrix renormalization group to matrix product states,\u201d Journal of Statistical\nMechanics: Theory and Experiment 2007, P10014, arXiv:cond-mat/0701428, (2007).\n25\n", "28": "4\nClassifying Gapped Phases in 1D\nMatrix product states are extremely useful in both analytic and numerical applications. One of the\nmost powerful results in the \ufb01eld of tensor network analytics is a complete classi\ufb01cation of gapped\nphases in 1D.\nTo begin this lecture, we will introduce quantum phases. We will then argue that in the absence of\nsymmetry constraints, all MPS are in the same phase. Finally, we will show how symmetries change\nthis classi\ufb01cation. Whilst interesting in it\u2019s own right, this material also serves to demonstrate the\nanalytic power of TNN.\n4.1\nQuantum Phases\nThe classical de\ufb01nition of a phase, or more particularly a phase transition, is usually associated to\nsome nonanalytic behaviour of the free energy density\nf(\u03b2, v) = \u2212log tr e\u2212\u03b2H(v)\n\u03b2\n,\n(4.1)\nwhere v is some vector of parameters of the model (pressures, masses, coupling strengths, etc.) and\nH the Hamiltonian of our system. Clearly when we take the quantum limit (\u03b2 \u2192\u221e), the free energy\nis simply the ground state energy. A quantum phase transition is thus associated with the ground\nstate [1].\nAt a classical phase transition, correlations become long ranged\n\u27e8O0Ox\u27e9\u2212\u27e8O0\u27e9\u27e8Ox\u27e9\u223c|x|\u2212\u03bd,\n(4.2)\nwhere the averages are taken with respect to some thermal distribution. We therefore say that a\nthermal (classical) phase transition is driven by thermal \ufb02uctuations, where the variance measures the\nincreasingly long range of these \ufb02uctuations. A quantum phase transition also has divergent correlation\nlength, however there is no thermal average \u2014 the statistics are purely quantum in origin [1].\nA classical phase corresponds to a range of deformations of H and \u03b2 which can be made without\ncausing nonanalyticities in the free energy f. Likewise, a quantum phase transition occurs where the\nground state energy becomes nonanalytic (in the thermodynamic limit) as a function of some Hamil-\ntonian parameters (not temperature this time!). Suppose we have a continuous family of quantum\nHamiltonians H(\u03bb). The lowest energy levels generically act in one of the following ways [1]:\n\u03bb\nE\n\u03bb\nE\nOn the left, there is no phase transition, whilst on the right a transition occurs when the roles of\nthe ground and \ufb01rst excited states cross.\nFor our purposes, a phase transition will be associated with a gapless point in the spectrum.\nTherefore, we will say that two states |\u03c80\u27e9and |\u03c81\u27e9are in the same phase if there is a continuous\nfamily of Hamiltonians H(\u03bb) such that |\u03c80\u27e9is the ground state of H(0), |\u03c81\u27e9is the ground state of\nH(1), and the gap remains open for all \u03bb \u2208[0, 1].\nAn equivalent notion is \ufb01nite time evolution under a local Hamiltonian [2]. Two states are in the\nsame phase if they can be interconverted by time evolution for a \ufb01nite period. This is linked to the\npossibility of one state naturally evolving into the other.\nIt is simpler, and essentially equivalent, to ask which states can be interconverted by a local\nquantum circuit of depth constant in the system size [3,4]. We will work within this framework. One\nmay also ask the more complicated question of how phases change if we impose a symmetry; if we insist\nthat all of the Hamiltonians H(\u03bb) commute with some symmetry group Ug(\u03bb). In the circuit picture,\nthis corresponds to restricting the gate set to only gates which commute with this symmetry [4\u20136].\n26\n", "29": "4.2\nInjective MPS\nIn this lecture, we will restrict ourselves to the case of injective MPS [7,8]. If we assume the MPS is\nin left canonical form\nd\u22121\nX\nj=0\nA\u2020\njAj = 1D\u00d7D\nor\n=\n,\n(4.3)\nthen injective MPS are those for which the identity is the unique eigenvalue 1 left eigenvector of the\ntransfer matrix. Moreover this means that there exists a unique full-rank5 density matrix \u03c1 which is\na 1 right eigenvector, i.e.\nd\u22121\nX\nj=0\nAj\u03c1A\u2020\nj =: E(\u03c1) = \u03c1\n(4.4)\n\u03c1\n=\n\u03c1 .\n(4.5)\nThese MPS correspond to unique gapped ground states of local Hamiltonians [9]. The arguments\nwe will present here generalise to non-injective MPS, however they become very technical.\n4.3\nNo Topological Order\nWe will refer to states which cannot be connected by any constant depth local circuit as being in\ndistinct topological phases, or having distinct topological order. This is to distinguish them from the\nsymmetric phases we will discuss later in this lecture. In fact, we will see that there are no nontrivial\ntopological phases in 1D [3].\nLet Aj de\ufb01ne some injective MPS, and construct the transfer matrix E6\nE =\n.\n(4.6)\nAs discussed in the previous lecture, this can be used to renormalise the MPS. Taking products of\nthis transfer matrix corresponds to blocking sites of the original MPS. Since the MPS is injective, the\nleading eigenvalue of E is 1 and all other eigenvalues are strictly smaller. Therefore, by taking the kth\npower of the transfer matrix, we obtain a new transfer matrix which is\nEk =\n\u03c1\n+ \u02dcO\n\u0010\n|\u03bb2|k\u0011\n,\n(4.7)\nwhere |\u03bb2| < 1 is the second eigenvalue of the transfer matrix and \u03c1 is the \ufb01xed point of the channel.\nThis transfer matrix can be decomposed to give a new e\ufb00ective MPS tensor describing the long\nwavelength physics\n\u02dcA =\n\u221a\u03c1\n.\n(4.8)\nOn the regions we blocked together, we could have \ufb01rst applied a unitary to the state without\nchanging the blocked transfer matrix. Since we only required a constant number of sites to be blocked\nto achieve this MPS tensor, this unitary freedom is restricted to a constant depth unitary circuit \u2013\nprecisely the equivalence we wish to allow. Now, let V be some unitary which acts as P\nj,k\n\u221a\u03c1j,k|j, k\u27e9\u2192\n5Were \u03c1 not full rank we could reduce the bond dimension such that it were without changing any observables in the\nthermodynamic limit.\n6Note that E is the \u2018Liouville superoperator\u2019 form of the channel E (Eqn. 4.4)\n27\n", "30": "|0, 0\u27e9on the state given by \u221a\u03c1 and arbitrarily on the rest of the space. We can now use this to apply\ntwo circuit layers to the MPS\n\u221a\u03c1\n\u221a\u03c1\nV\n\u221a\u03c1\nV\n\u221a\u03c1\nV\n\u221a\u03c1\nV\n\u221a\u03c1\nV\n\u221a\u03c1\nV\n,\n(4.9)\nwhich completely disentangles the MPS, giving the state |00 \u00b7 \u00b7 \u00b7 0\u27e9.\nNotice that this was all achieved by simply blocking a constant number of sites together, so we have\nonly used a constant depth quantum circuit. Therefore, all injective MPS are in the same (topological)\nphase as the product state, and therefore each other.\n4.4\nSymmetry Respecting Phases\nThe proofs in this section are translated into TNN from Ref. [8].\nSince there are no nontrivial topological phases, we will now examine what happens when a sym-\nmetry restriction is imposed on the allowed gates. Let G be some symmetry group for a state which\nacts on-site as Ug := u\u2297n\ng\nfor each g \u2208G, where ug is a unitary representation of G acting on a single\nsite. Recall that for ug to be a representation, we must have\nuguh = ugh\n(4.10)\nfor all g, h \u2208G.\nLet A be an MPS tensor such that |\u03c8[A]\u27e9is symmetric, meaning that Ug|\u03c8[A]\u27e9= ei\u03c6g|\u03c8[A]\u27e9for\nall g \u2208G. We will now examine how this symmetry is realised on the MPS tensor itself.\nWe require an understanding of the action of unitaries on the physical level of an MPS, and when\nthey can be \u2018pushed through\u2019 to act on the virtual level. There, they won\u2019t be touched by the action\nof constant depth symmetric circuits on the physical legs, so any properties associated with the virtual\naction of the symmetry will be an invariant of the phase.\nWe require two lemmas.\nLemma 1. Let u be some unitary and A an injective MPS tensor. Then the largest eigenvalue \u03bb of\nthe u-transfer matrix\nEu =\nu\n(4.11)\nis contained within the unit disk.\nProof. Let v\u2020 (note that we are not assuming that this is unitary) be a left eigenvector of Eu\nv\u2020\nu\n= \u03bb\nv\u2020\n.\n(4.12)\nWe therefore get for some density matrix \u03c1\n\u03bb\nv\u2020\nv\n\u03c1\n=\nv\u2020\nv\nu\n\u03c1 .\n(4.13)\n28\n", "31": "Once again let \u03c1 be the (unique) right eigenvector of E with eigenvalue 1. We can view the above\nexpression as an inner product between two vectors\n\u03bb\nv\u2020\nv\n\u03c1\n=\nv\u2020\nv\n\u221au\n\u221au\n\u221a\u03c1\n\u221a\u03c1\n.\n(4.14)\nWe can now apply the Cauchy-Schwarz inequality across the dotted line, giving\n\f\f\f\f\f\f\f\f\f\f\f\f\f\f\f\nv\u2020\nv\n\u221au\n\u221au\n\u221a\u03c1\n\u221a\u03c1\n\f\f\f\f\f\f\f\f\f\f\f\f\f\f\f\n2\n\u2264\nv\u2020\nv\n\u221au\n\u221au\u2020\n\u221a\u03c1\n\u221a\u03c1\n\u00d7\nv\nv\u2020\n\u221au\u2020\n\u221au\n\u221a\u03c1\n\u221a\u03c1\n(4.15)\n=\nv\u2020\nv\n\u03c1\n\u00d7\nv\nv\u2020\n\u03c1\n(4.16)\n=\nv\u2020\nv\n\u03c1\n\u00d7\nv\u2020\nv\n\u03c1\n(4.17)\nwhere the vertical lines indicate absolute value. Thus we have\n|\u03bb|\nv\u2020\nv\n\u03c1\n\u2264\nv\u2020\nv\n\u03c1 ,\n(4.18)\nand so |\u03bb| \u22641. \u25a1\nLemma 2. Equality is achieved in Lemma 1 if and only if there exists a unitary v and an angle \u03b8\nsuch that\nu\n= ei\u03b8\nv\nv\u2020\n.\n(4.19)\nProof. First we prove the \u2018if\u2019 direction. Assume that Eqn. 4.19 holds. Then\nv\u2020\nu\n= ei\u03b8\nv\u2020\n(4.20)\n=\u21d2\nv\u2020\nu\n= ei\u03b8\nv\u2020\n(4.21)\n=\u21d2\nv\u2020\nu\n= ei\u03b8\nv\u2020\n,\n(4.22)\n29\n", "32": "and so we have found a left eigenvector v\u2020 of Eu with a modulus 1 eigenvalue of \u03bb = ei\u03b8.\nNow we prove the \u2018only if\u2019 direction. Assume there exists a left eigenvector v\u2020 with eigenvalue of\nmodulus 1, then the Cauchy-Schwarz inequality Eqn. 4.15 must become an equality. Therefore, there\nis some scalar \u03b1 such that\nv\n\u221au\n\u221a\u03c1\n= \u03b1\nv\n\u221au\u2020\n\u221a\u03c1\n.\n(4.23)\nTaking the norm of each side as vectors, we have\nv\n\u221au\nv\u2020\n\u221au\u2020\n\u221a\u03c1\n\u221a\u03c1\n= |\u03b1|2\nv\n\u221au\u2020\nv\u2020\n\u221au\n\u221a\u03c1\n\u221a\u03c1\n(4.24)\n=\u21d2\nv\u2020\nv\n\u03c1\n= |\u03b1|2\nv\u2020\nv\n\u03c1\n(4.25)\n=\u21d2\nv\u2020\nv\n\u03c1\n= |\u03b1|2\nv\u2020\nv\n\u03c1 .\n(4.26)\nTherefore, |\u03b1| = 1, so \u03b1 = ei\u03b8.\nSince \u03c1 is full rank, it is invertible, so\nv\n\u221au\n= ei\u03b8\nv\n\u221au\u2020\n.\n(4.27)\nNow, rearranging this and left multiplying by v\u2020, we have\nv\u2020\nv\nu\n= ei\u03b8\nv\u2020\nv\n(4.28)\n=\u21d2\nv\u2020\nv\nu\n= ei\u03b8\nv\u2020\nv\n(4.29)\n=\u21d2\u03bb\nv\u2020\nv\n= ei\u03b8\nv\u2020\nv\n.\n(4.30)\nWe therefore see that v\u2020v is a left eigenvector of the transfer matrix E with norm-1 eigenvalue. By\nassuming injectivity however we require that the only norm-1 eigenvalue is the non-degenerate +1\neigenvalue, whose left eigenvector is the identity. Thus we conclude v is, after rescaling, unitary, and\nthat Eqn. 4.19 therefore holds. \u25a1\nSo far, we have established that a unitary u can be \u2018pushed through\u2019 the MPS tensor if and only\nif the u-transfer matrix has an eigenvalue of unit magnitude. We will now show that u is a local\nsymmetry if and only if it can be pushed through. This will complete our understanding of the action\nof local symmetries on MPS tensors.\n30\n", "33": "Theorem 1 (Symmetries push through). Let G be a group. A unitary representation ug is a local\nsymmetry if and only if\nug\n= ei\u03b8g\nvg\nv\u2020\ng\n(4.31)\nfor vg unitary and \u03b8g \u2208[0, 2\u03c0).\nProof. If Eqn. 4.31 holds, it is clear that ug is a symmetry since vg is simply a gauge transformation\non the MPS.\nLet\n\u03c3k =\n\u03c1\n\u00b7 \u00b7 \u00b7\n\u00b7 \u00b7 \u00b7\n(4.32)\nbe the reduced density matrix on k sites, where \u03c1 is the right \ufb01xed point of E. By construction,\ntr(\u03c3k) = 1, but \u03c3k will generically be mixed, so tr(\u03c32\nk) \u22641. Recall that the purity of a density matrix\nis lower bounded by the inverse of the matrix-rank, i.e. tr(\u03c32\nk) \u22651/rank(\u03c3k). Since our reduced density\nmatrix is obtained from a bond dimension D MPS, it has rank at most D2. Therefore\n1\nD2 \u2264tr\n\u0000\u03c32\nk\n\u0001\n=\n\u03c1\n\u00b7 \u00b7 \u00b7\n\u00b7 \u00b7 \u00b7\n\u03c1\n\u00b7 \u00b7 \u00b7\n\u00b7 \u00b7 \u00b7\n(4.33)\n=\n\u03c1\n\u00b7 \u00b7 \u00b7\n\u00b7 \u00b7 \u00b7\n\u03c1\n\u00b7 \u00b7 \u00b7\n\u00b7 \u00b7 \u00b7\nug\nu\u2020\ng\nug\nu\u2020\ng\nug\nu\u2020\ng\nug\nu\u2020\ng\n(4.34)\n=\nug\nu\u2020\ng\nug\nu\u2020\ng\nug\nu\u2020\ng\nug\nu\u2020\ng\n\u00b7 \u00b7 \u00b7\n\u00b7 \u00b7 \u00b7\n\u03c1\n\u03c1\n\u00b7 \u00b7 \u00b7\n\u00b7 \u00b7 \u00b7\n,\n(4.35)\nwhere the second equality holds because ug is a local symmetry.\nHere, the left and right boundary vectors (1 and \u03c1) are independent of the number of sites upon\nwhich \u03c3k is supported, so this inequality holds for all k. This can only be the case if Eug has an\n31\n", "34": "eigenvalue of magnitude 1, as it would otherwise have to possess exponential decay. From Lemma 2,\nthis implies that there exists some unitary vg and an angle \u03b8g such that\nug\n= ei\u03b8g\nvg\nv\u2020\ng\n(4.36)\nwhich completes the proof. \u25a1\nWe now investigate the properties of the virtual action of the symmetry. As discussed above, if we\napply a constant depth circuit with symmetric gates to the MPS (i.e. mapping us to any other state\nin the phase), we can push the symmetry action \ufb01rst through the circuit and then onto the virtual\nlevel. Therefore, any properties it has will be an invariant of the phase.\nAside 2 : Projective representations\nLet G be some group. A (linear) representation ug obeys\nuguh = ugh\n\u2200g, h \u2208G.\n(4.37)\nThis is not the most general way of acting with a group however. We could also ask for\nvgvh = \u03c9[g, h]vgh\n\u2200g, h \u2208G,\n(4.38)\nwhere \u03c9[g, h] = ei\u03c6[g,h] is a scalar which depends on both g and h independently. This is known\nas a projective representation. One might ask whether this is simply a more complicated way of\nwriting a linear representation. Maybe we can rephase vg to obtain Eqn. 4.37. Let \u03b2[g] be some\nphase depending only on g then after a rephasing vg 7\u2192\u03b2[g]vg, we have\nvgvh = \u03c9[g, h] \u03b2[gh]\n\u03b2[g]\u03b2[h]vgh = \u03c9\u2032[g, h]vgh.\n(4.39)\nWe say that \u03c9 and \u03c9\u2032 are equivalent if they are related in this way, so\n\u03c9 \u223c\u03c9\u2032 \u21d0\u21d2\u2203\u03b2 : \u03c9\u2032[g, h] =\n\u03b2[gh]\n\u03b2[g]\u03b2[h]\u03c9[g, h].\n(4.40)\nA projective representation is therefore equivalent to a linear representation if the phases can be\ncompletely removed, i.e. there exists a \u03b2 such that\n\u03c9[g, h] = \u03b2[g]\u03b2[h]\n\u03b2[gh] .\n(4.41)\nAs you will show in Problems 4, there are projective representations which are not equivalent to\nany linear representation.\nSuppose we act with ug followed by uh on the MPS tensor, then\nug\nuh\n= ei\u03b8g\nvg\nv\u2020\ng\nuh\n= ei\u03b8gei\u03b8h\nvh\nv\u2020\nh\nvg\nv\u2020\ng\n.\n(4.42)\nWe could also have combined uguh = ugh before pushing through, which tells us\nugh\n= ei\u03b8gh\nvgh\nv\u2020\ngh\n.\n(4.43)\n32\n", "35": "Therefore\n(vg \u2297v\u2020\ng)(vh \u2297v\u2020\nh) =\nei\u03b8gh\nei\u03b8gei\u03b8h vgh \u2297v\u2020\ngh,\n(4.44)\nso (vg \u2297v\u2020\ng) is equivalent to a linear representation. We can split this across the tensor product, telling\nus that in general\nvgvh = \u03c9[g, h]vgh,\n(4.45)\nwhere \u03c9 is some phase. We cannot say anything about the phase in this case, since anything would\nbe cancelled by tensoring with the conjugate.\nThe only freedom we have to change vg within a phase is local rephasing, therefore the equivalence\nclasses of \u03c9 label the di\ufb00erent phases of injective MPS with a symmetry restriction. These equivalence\nclasses are indexed by the so-called second group cohomology class of the group G, an object usually\nwritten as H2(G, U(1)) [2,10].\nProblems 4\nSolutions in accompanying document.\n1. The group Z2 \u00d7 Z2 has the presentation Z2 \u00d7 Z2 = \u27e8x, z|x2 = z2 = e, xz = zx\u27e9. Show that\nthe Pauli matrices form a projective representation of Z2 \u00d7 Z2.\nHint: let vx = X, vz = Z, vxz=zx = Y and show that vgvh = \u03c9[g, h]vgh, where \u03c9 is some\nphase.\n2. Determine the factor system \u03c9[g, h] for the Pauli matrices.\n3. Show that the Pauli projective representation is not equivalent to a linear representation.\nHint: xz = zx, can we rephase vx and vz to make vxvz \u2212vzvx = 0?\n4. Recall from Sec. 3.2 that the symmetry of the cluster state is Z2 \u00d7 Z2, with the action on\nthe MPS tensor being\nX\n=\nZ\nZ\n,\nX\n=\nX\nX\n.\n(4.46)\nWhat can we conclude about the cluster state?\n4.6\nReferences\n[1] S. Sachdev, Quantum phase transitions 2nd edition, Cambridge University Press, (2011).\n[2] X. Chen, Z. C. Gu, and X. G. Wen, \u201cClassi\ufb01cation of Gapped Symmetric Phases in 1D Spin Systems,\u201d Physical\nReview B 83, 035107, arXiv:1008.3745, (2011).\n[3] X. Chen, Z. C. Gu, and X. G. Wen, \u201cLocal unitary transformation, long-range quantum entanglement, wave function\nrenormalization, and topological order,\u201d Physical Review B 82, 155138, arXiv:1004.3835, (2010).\n[4] Y. Huang, and X. Chen, \u201cQuantum circuit complexity of one-dimensional topological phases,\u201d Physical Review B\n91, 195143, arXiv:1401.3820, (2015).\n[5] X. Chen, Z. C. Gu, Z. X. Liu, and X. G. Wen, \u201cSymmetry protected topological orders and the group cohomology\nof their symmetry group,\u201d Physical Review B 87, 155114, arXiv:1106.4772, (2011).\n[6] \u201cCan a symmetry-preserving unitary transformation that goes from a trivial SPT to a non-trivial SPT be lo-\ncal?,\u201d\nStack Exchange - http://physics.stackexchange.com/questions/184570/can-a-symmetry-preserving-unitary-\ntransformation-that-goes-from-a-trivial-spt-to, (2015).\n[7] D. Perez-Garcia, F. Verstraete, M. M. Wolf, and J. I. Cirac, \u201cMatrix Product State Representations,\u201d Quantum\nInformation & Computation 7, 401\u2013430, arXiv:quant-ph/0608197, (2007).\n33\n", "36": "[8] D. P\u00b4erez-Garc\u00b4\u0131a, M. M. Wolf, M. Sanz, F. Verstraete, and J. Cirac, \u201cString Order and Symmetries in Quantum Spin\nLattices,\u201d Physical Review Letters 100, 167202, arXiv:0802.0447v1, (2008).\n[9] N. Schuch, I. Cirac, and D. P\u00b4erez-Garc\u00b4\u0131a, \u201cPEPS as ground states: Degeneracy and topology,\u201d Annals of Physics\n325, 2153\u20132192, arXiv:1001.3807, (2010).\n[10] N. Schuch, D. P\u00b4erez-Garc\u00b4\u0131a, and I. Cirac, \u201cClassifying quantum phases using matrix product states and projected\nentangled pair states,\u201d Physical Review B 84, 165139, arXiv:1010.3732, (2011).\n34\n", "37": "5\nTensor network algorithms\nOne area in which tensor networks have had exceptional practical success is in low-temperature sim-\nulation of condensed matter systems. A relatively well-understood toy model is \ufb01nding ground states\nof one-dimensional spin systems. Even under the assumption of a local Hamiltonian, this seemingly\nnarrow problem retains QMA-completeness [1] (a quantum analogue of NP), dashing any hope of gen-\neral simulation, even on a quantum computer. Whilst this may at \ufb01rst seem like a signi\ufb01cant problem,\nmany \u2018physically realistic\u2019 systems don\u2019t exhibit this prohibitive complexity. Tensor networks can be\nused to exploit, and to a certain extent understand, this structure.\nAs discussed previously, states of low entanglement are well represented in the form of MPS. If we\nconsider the case of local and gapped Hamiltonians, it has been shown that the relevant ground states\ncannot be highly entangled [2\u20135, 12] (see Ref. [6] for a review). This restricted entanglement means\nthat such states admit e\ufb03cient MPS approximations [7], and moreover that they may be e\ufb03ciently\napproximated [8\u201312], showing that the presence of the gap causes the complexity to plummet from\nQMA-complete all the way down to P, removing the complexity barrier to simulation. We note that\ndespite the challenges, both complexity theoretic and physical, in applying MPS to gapless models,\nthey have been successfully utilised for this purpose [13\u201315].\nMore concretely, the way in which we plan to approximate the ground state is by minimising\nthe Rayleigh quotient of the Hamiltonian H (the energy) over some restricted domain D to yield an\napproximate ground state |\u0393\u27e9given as\n|\u0393\u27e9:= arg min\n|\u03c8\u27e9\u2208D\n\u27e8\u03c8|H|\u03c8\u27e9\n\u27e8\u03c8|\u03c8\u27e9.\n(5.1)\nAs we know that the exact solution is well-approximated by MPS, we will restrict ourselves to the\ndomain D of MPS of a bounded bond dimension. The idea behind DMRG and TEBD is to start in\nsome MPS state7 then variationally move along this domain, minimising the energy as we go. The\ndi\ufb00erence between both methods is the manner in which this variation step is performed, with DMRG\nand TEBD taking more computational and physical approaches respectively.\nAlthough the algorithms we discuss here are designed for \ufb01nding MPS ground states, they can be\nadaped to simulate time evolution [16,17], \ufb01nd Gibbs states [18], or optimise other operators acting\non a statespace of interest [19].\n5.1\nDMRG (The Computer Scientist\u2019s approach)\nBy far the most studied and successful of the algorithms in the \ufb01eld is DMRG. For clarity we will\nbe restricting ourselves to \ufb01nite DMRG, though there do exist thermodynamic variants. DMRG is\nan umbrella term which encompasses several similar algorithms, the algorithm we will discuss here\nis a simpli\ufb01ed but nonetheless e\ufb00ective example. As the introduction of this algorithm in Ref. [20]\npre-dates TNN, its description has historically been presented in a far more physically motivated\nand technically complicated manner. Due to the corresponding shift in interpretation, the original\nacronym now holds little relevance to the modern tensor network interpretation of DMRG, and so for\nclarity we intentionally omit de\ufb01ning precisely the expansion of DMRG as an acronym8. For a full\nreview in pre-TNN notation see Ref. [21], and see Ref. [22] for a TNN treatment.\nRepresenting the Hamiltonian by an MPO, optimising the Rayleigh quotient over MPS looks like\nthe following:\narg min\n1\n1\n2\n2\n3\n3\n4\n4\n5\n5\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7\nn\nn\n,\n1\n1\n2\n2\n3\n3\n4\n4\n5\n5\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7\nn\nn\n(5.2)\nThe di\ufb03culty is that as we need the contraction of these MPS tensors; the overall objective function\nis highly non-linear, but it does however only depend quadratically on each individual tensor. The\n7Typically a random MPS is su\ufb03cient in practice, though one could use an educated guess if available.\n8Though a curious reader is free to Google it, at their own peril.\n35\n", "38": "key heuristic behind DMRG is to exploit the simplicity of these local problems, approximating the\nmultivariate (multi-tensor) optimisation by iterated univariate (single tensor) optimisations.\nNote that while the DMRG algorithm we are going to outline only calculates ground states, related\ngeneralisations exist which can be used to simulate excited states, dynamics etc.\n5.1.1\nOne-site\nThe simplest interpretation of the above sketch of DMRG is known as DMRG1 (or one-site DMRG).\nFor a \ufb01xed site i, the sub-step involves \ufb01xing all but a single MPS tensor, which is in turn optimised\nover, i.e.\nAi \u2190\u2212arg min\nAi\n\u27e8\u03c8(Ai)|H|\u03c8(Ai)\u27e9\n\u27e8\u03c8(Ai)|\u03c8(Ai)\u27e9.\n(5.3)\nIn TNN these step look like:\ni\n\u2190\u2212arg min\ni\ni\ni\n,\ni\ni\n(5.4)\nNext we de\ufb01ne the environment tensors\nHi\n:=\n,\n(5.5)\nIi\n:=\n,\n(5.6)\nwhich correspond to taking closed tensor networks \u2014 the expectation values of H and the I respectively\n\u2014 and removing the objective tensor. Given these environments, the sub-step in Eq. (5.4) becomes\ni\n\u2190\u2212arg min\ni\nHi\ni\ni\n,\nIi\ni\ni\n.\n(5.7)\nVectorising this equation yields\nAi \u2190\u2212arg min\nAi\n\u27e8Ai|Hi|Ai\u27e9\n\u27e8Ai|Ii|Ai\u27e9.\n(5.8)\nFinally we can simplify the denominator of this objective function by appropriately gauge-\ufb01xing\nour MPS to be in canonical form. By putting the parts of the MPS left of our site in left-canonical\nform, and those to the right in right-canonical form, then we get that Ii simply reduces to the identity:\nIi\n=\n=\n= \u00b7 \u00b7 \u00b7 =\n(5.9)\n36\n", "39": "Given this canonicalisation, the problem thus reduces to\nAi \u2190\u2212arg min\nAi\n\u27e8Ai|Hi|Ai\u27e9\n\u27e8Ai|Ai\u27e9\n.\n(5.10)\nAs Hi is Hermitian, this optimisation has a closed form solution given by the minimum eigenvector9\nof Hi. By sweeping back and forth along the chain, solving this localised eigenvector problem, and\nthen shifting along the canonicalisation as necessary, we complete our description of the algorithm.\nThe main advantage of DMRG1 is that the state stays within the MPS manifold without the\nbond dimension growing, meaning that the algorithm is greedy10. This strict restriction on the bond\ndimension can however be a double-edged sword; this means that there is no particularly convenient\nmethod of gently growing the bond dimension as the algorithm runs11, and no information is gained\nregarding the appropriateness of the choice of bond dimension. Both of these problems are addressed\nin turn by the improved, albeit slightly more complicated, DMRG2 algorithm.\n5.1.2\nTwo-site\nThe idea with DMRG2 is to block two sites together, perform an optimisation in the vein DMRG1,\nthen split the sites back out. This splitting process gives DMRG2 its power, allowing for dynamic\ncontrol of the bond dimension, as well as providing information about the amount of error caused by\ntrimming, which helps to inform the choice of bond-dimension.\nFirst an optimisation is performed:\ni,i+1\ni,i+1\n\u2190\u2212arg min\ni,i+1\ni,i+1\ni,i+1\n,\ni,i+1\ni,i+1\n(5.11)\nwhich can once again be solved by taking the minimum eigenvector of an environment tensor with\nrespect to two sites, Hi,i+1, once again in mixed canonical form. After this the two-site tensor is split\napart by performing an SVD12 and a bond trimming:\ni,i+1\ni,i+1\nSVD\n\u2212\u2212\u2212\u2192\nTrim\ni\ni+1\nThis trimmed SVD has two key features. Firstly the bond dimension to which we trim could\nbe higher than that we originally started with, allowing us to gently expand out into the space of\nhigher bond dimension MPS. Secondly we can use the truncated singular values to quantify the error\nassociated with this projection back down into the lower bond dimension space, better informing our\nchoice of bond dimension.\n5.2\nTEBD (The Physicist\u2019s approach)\nTime-evolving block decimation (TEBD) [27, 28] is a tensor network algorithm that allows the dy-\nnamics of 1D spin systems to be simulated. By simulating imaginary-time-evolution low-temperature\nfeatures such as the ground state may be calculated as well.\n9If we had not canonicalised the MPS then a closed form solution still exists in the form of the generalised eigenvector\nof Hi and Ii, but in general the cost of canonicalisation is well-justi\ufb01ed by the increased stability it yields.\n10A greedy algorithm is one which solves local problems, such that the cost function (energy in this case) monotonically\ndecreases.\n11There are however somewhat involved methods that allow for auxiliary data to be injected in a non-local fashion\nsuch as Refs. [23,24] (see Ref. [25] for a review), achieving a similar goal.\n12Whilst other factorisations such as QR and LU can also be used, SVD is preferred over other rank-revealing decom-\npositions due to the optimality of singular value truncation as a low-rank approximation (see Aside 1).\n37\n", "40": "To simulate imaginary-time-evolution, we need to approximate the imaginary-time-evolution op-\nerator U(\u03c4) = exp(\u2212\u03c4H). The problem here is that whilst we may have an e\ufb03cient representation of\nH, any exponential of it will not necessarily have a succinct representation. Take the example of a\ntwo-body Hamiltonian with corresponding imaginary-time-evolution operator\nU(\u03c4) = e\u2212\u03c4 P\ni hi\nwhere\nH =\nX\ni\nhi\nand hi is an interaction term acting on spins i and i + 1. Whilst H has a constant Schmidt rank,\nadmitting an e\ufb03cient representation as an MPO, U(\u03c4) generically has exponential bond dimension\nfor almost all \u03c4.\nLet Ho(He) denote the sum of terms hi for odd(even) i.\nAs all the terms within Ho(He) are\ncommuting, e\u2212\u03c4Ho(e\u2212\u03c4He) can be e\ufb03ciently computed and represented. The problem of approximating\nU(\u03c4) can therefore be reduced to the problem of approximating e\u2212t(A+B) when only terms of the form\ne\u2212\u03c4A and e\u2212\u03c4B can be computed.\nThe central mathematical tool to TEBD are the exponential product approximations. The \ufb01rst\norder of these approximation is the Suzuki-Trotter formula, which approximates the total evolution\nby simply evolving each subsystem:\ne\u2212\u03c4(A+B) = e\u2212\u03c4Ae\u2212\u03c4B + O(\u03c4 2) .\nIt turns out there exist entire families of such approximations [29], though for our purposes we will\njust illustrate the procedure for Suzuki-Trotter.\nThe TEBD algorithm works by approximating the imaginary-time-evolution operator by the above\nexponential product formulae, applying it to a given MPS, and trimming the bond dimension to project\nback down into the space of MPS.\nOur approximation to the imaginary-time-evolution operator is given by a product of layers con-\ntaining only nearest-neighbour two-site operators, meaning we need only be able to contract these\noperators into our MPS. Suppose we want to apply an operator U to the spins at sites i and i + 1.\nThe idea is to apply the operator, contract everything into a single tensor, then once again use an\nSVD trimming to truncate the bond dimension back down.\ni\ni+1\nU\nCont.\n==\ni,i+1\nSVD\n\u2212\u2212\u2212\u2192\nTrim\ni\ni+1\n(5.12)\nThe bene\ufb01ts this trimming procedure gave to DMRG2 \u2014 namely control over bond dimension growth\nand quanti\ufb01cation of trimming errors \u2014 are also seen in TEBD. As the above procedure is entirely\nlocalised, TEBD also admits a large amount of parallelisation, not typically available to DMRG.\n5.3\nImplementation\nFrom-scratch implementation of these simple algorithms can be achieved with relative ease, however\nseveral high performance libraries exist for research level simulations. We direct the interested reader\nto investigate ITensor [30] (C++), evoMPS [31] (Python), Matrix Product Toolkit [32] (C++), uni10\n(C++) [33], Tensor Operations [34] (Julia) among others. A simple tensor class can also be easily\nwritten in MATLAB.\nProblems 5\nSolutions in accompanying document.\n38\n", "41": "1. Consider the critical transverse Ising model\nH = \u2212\nn\u22121\nX\ni=1\nXiXi+1 \u2212\nn\nX\ni=1\nZi.\n(5.13)\nFor open boundary conditions, it is known that the ground state energy as a function of n\nhas the form [35]\nE(n) = 1 \u2212csc\n\u0012\n\u03c0\n\u03b1n + \u03b2\n\u0013\n(5.14)\nfor some integers \u03b1 and \u03b2. Using either DMRG or TEBD, estimate the ground state energy\nfor several chain lengths and calculate \u03b1 and \u03b2.\n2. It is known that the Local Hamiltonian problem is in P for 1D gapped Hamiltonians [8\u2013\n12]. DMRG and TEBD are the most common techniques for numerically \ufb01nding the ground\nstates of such systems. For a gapped and 1D local Hamiltonian, prove that DMRG or TEBD\nconverge.\n5.5\nReferences\n[1] A. Y. Kitaev, A. H. Shen, and M. N. Vyalyi, Classical and Quantum Computation, Graduate Studies in Mathe-\nmatics, AMS, (2002).\n[2] M. B. Hastings, \u201cAn area law for one-dimensional quantum systems,\u201d Journal of Statistical Mechanics 2007, P08024,\narXiv:0705.2024, (2007).\n[3] I. Arad, Z. Landau, and U. Vazirani, \u201cImproved one-dimensional area law for frustration-free systems,\u201d Physical\nReview B 85, 195145, arXiv:1111.2970, (2012).\n[4] I. Arad, A. Kitaev, Z. Landau, and U. Vazirani, \u201cAn area law and sub-exponential algorithm for 1D systems,\u201d\narXiv:1301.1162, (2013).\n[5] Y. Huang, \u201cArea law in one dimension: Renyi entropy and degenerate ground states,\u201d arXiv:1403.0327, (2014).\n[6] J. Eisert, M. Cramer, and M. B. Plenio, \u201cColloquium: Area laws for the entanglement entropy,\u201d Reviews of Modern\nPhysics 82, 277\u2013306, arXiv:0808.3773, (2010).\n[7] F. Verstraete and J. Cirac, \u201cMatrix product states represent ground states faithfully,\u201d Physical Review B 73, 094423,\narXiv:cond-mat/0505140, (2006).\n[8] Z. Landau, U. Vazirani, and T. Vidick, \u201cA polynomial-time algorithm for the ground state of 1D gapped local\nHamiltonians,\u201d Proceedings of the 5th Conference on Innovations in Theoretical Computer Science and Nature\nPhysics 11, 566\u2013569, arXiv:1307.5143, (2013).\n[9] C. T. Chubb and S. T. Flammia, \u201cComputing the Degenerate Ground Space of Gapped Spin Chains in Polynomial\nTime,\u201d Chicago Journal of Theoretical Computer Science 2016, 9, arXiv:1502.06967, (2016).\n[10] Y. Huang, \u201cA polynomial-time algorithm for approximating the ground state of 1D gapped Hamiltonians,\u201d\narXiv:1406.6355, (2014).\n[11] Y. Huang, \u201cComputing energy density in one dimension,\u201d arXiv:1505.00772, (2015).\n[12] I. Arad, Z. Landau, U. Vazirani, and T. Vidick, \u201cRigorous RG algorithms and area laws for low energy eigenstates\nin 1D,\u201d arXiv:1602.08828, (2016).\n[13] L. Tagliacozzo, T. R. de Oliveira, S. Iblisdir, and J. I. Latorre, \u201cScaling of entanglement support for Matrix Product\nStates,\u201d Physical Review B 78, 024410, arXiv:0712.1976, (2008).\n[14] F. Pollmann, S. Mukerjee, A. Turner, and J. E. Moore, \u201cTheory of \ufb01nite-entanglement scaling at one-dimensional\nquantum critical points,\u201d Physical Review Letters 102, 255701, arXiv:0812.2903, (2008).\n[15] V. Stojevic, J. Haegeman, I. P. McCulloch, L. Tagliacozzo, and F. Verstraete, \u201cConformal Data from Finite Entan-\nglement Scaling,\u201d Physical Review B 91, 035120, arXiv:1401.7654, (2015).\n[16] A. J. Daley, C. Kollath, U. Schollwoeck, and G. Vidal, \u201cTime-dependent density-matrix renormalization-group\nusing adaptive e\ufb00ective Hilbert spaces,\u201d Journal of Statistical Mechanics: Theory and Experiment 2004, P04005,\narXiv:cond-mat/0403313, (2004).\n[17] S. R. White, and A. E. Feiguin, \u201cReal-Time Evolution Using the Density Matrix Renormalization Group,\u201d Physical\nReview Letters 93, 076401, arXiv:cond-mat/0403310, (2004).\n[18] F. Verstraete, J. J. Garc\u00b4\u0131a-Ripoll, and J. I. Cirac, \u201cMatrix Product Density Operators: Simulation of \ufb01nite-T and\ndissipative systems,\u201d Physical Review Letters 93, 207204, arXiv:cond-mat/0406426, (2004).\n39\n", "42": "[19] J. C. Bridgeman, S. T. Flammia, and D. Poulin, \u201cDetecting Topological Order with Ribbon Operators,\u201d Physical\nReview B 93, 207204, arXiv:1603.02275, (2016).\n[20] S. R. White, \u201cDensity matrix formulation for quantum renormalization groups,\u201d Physical Review Letters 69, 2863\u2013\n2866, (1992).\n[21] U. Schollw\u00a8ock, \u201cThe density-matrix renormalization group,\u201d Reviews of Modern Physics 77, 259\u2013315, arXiv:cond-\nmat/0409292, (2005).\n[22] U. Schollw\u00a8ock, \u201cThe density-matrix renormalization group in the age of matrix product states,\u201d Annals of Physics\n326, 96\u2013192, arXiv:1008.3477, (2011).\n[23] S. R. White, \u201cDensity matrix renormalization group algorithms with a single center site,\u201d Physical Review B 72,\n180403, arXiv:cond-mat/0508709, (2005).\n[24] S. V. Dolgov and D. V. Savostyanov, \u201cAlternating Minimal Energy Methods for Linear Systems in Higher Dimen-\nsions,\u201d SIAM Journal on Scienti\ufb01c Computing 36, A2248\u2013A2271, arXiv:1301.6068, (2014).\n[25] S. V. Dolgov and D. V. Savostyanov, \u201cOne-site density matrix renormalization group and alternating minimum\nenergy algorithm,\u201d Numerical Mathematics and Advanced Applications, arXiv:1312.6542, (2013).\n[26] C. Eckart and G. Young, \u201cThe approximation of one matrix by another of lower rank,\u201d Psychometrika 1, (1936).\n[27] G. Vidal, \u201cE\ufb03cient Classical Simulation of Slightly Entangled Quantum Computations,\u201d Physical Review Letters\n91, 147902, arXiv:quant-ph/0301063, (2003).\n[28] G. Vidal, \u201cE\ufb03cient Simulation of One-Dimensional Quantum Many-Body Systems,\u201d Physical Review Letters 93,\n40502, arXiv:quant-ph/0310089, (2004).\n[29] N. Hatano and M. Suzuki, \u201cFinding Exponential Product Formulas of Higher Orders,\u201d Quantum Annealing and\nOther Optimization Methods, arXiv:math-ph/0506007, (2005).\n[30] ITensor http://itensor.org/\n[31] evoMPS http://amilsted.github.io/evoMPS/\n[32] Matrix Product Toolkit http://physics.uq.edu.au/people/ianmcc/mptoolkit/index.php\n[33] uni10 http://uni10.org/\n[34] Tensor Operations https://github.com/Jutho/TensorOperations.jl\n[35] N. S. Izmailian and C.-K. Hu, \u201cBoundary conditions and amplitude ratios for \ufb01nite-size corrections of a one-\ndimensional quantum spin model,\u201d Nuclear Physics B 808, 613, arXiv:1005.1710, (2009).\n40\n", "43": "6\nProjected Entangled Pair States\nMany of the ideas behind MPS generalise to higher dimensions via projected entangled pair states or\nPEPS [1,2]. We will see how this is a misnomer in two ways, there is not necessarily a projector and\nthere is not necessarily an entangled pair.\nWe begin by recalling the PEPS description of matrix product states, then generalise this to two\ndimensional models. After giving several examples, we will examine the properties of PEPS, identifying\nboth the similarities and di\ufb00erences to MPS.\n6.1\nOne Dimensional Systems: MPS\nWe have already seen the PEPS construction in 1D. Let |\u03c6\u27e9\u2208CD \u2297CD be some (usually) entangled\npair and P : CD \u2297CD \u2192Cd some linear map. Then\n|\u03c8\u27e9=\nP\nP\nP\nP\nP\nP\nP\nP\nP\n,\n(6.1)\nwhere\n|\u03c6\u27e9=\n(6.2)\nis the chosen entangled pair. As we saw, we have a large choice in the exact description we use. We\ncan transform the local basis of each spin in the entangled pair by any (left) invertible matrix\n|\u03c6\u27e9\u2192(A \u2297B)|\u03c6\u27e9,\n(6.3)\nsince we can modify P to compensate\nP \u2192P(B\u22121 \u2297A\u22121).\n(6.4)\nOne thing to note is that |\u03c6\u27e9does not necessarily need to be a valid quantum state. We usually leave\nit unnormalised for convenience.\nIn addition to this gauge freedom, we have additional choices in the description. We could use\nentangled triplets for example. Let |\u03c8\u27e9= |000\u27e9+ |111\u27e9, then we could choose our PEPS to be\n|\u03c8\u27e9\n=\nP\nP\nP\nP\nP\n.\n(6.5)\nClearly this doesn\u2019t o\ufb00er any more descriptive power than using entangled pairs. Suppose we have\nsome PEPS projector Q acting on pairs, then we can extend this to a P acting on triplets by\nP = Q (1 \u2297(|0\u27e9\u27e800| + |1\u27e9\u27e811|)) .\n(6.6)\nIn the other direction, we can build a product of triplets using a minor modi\ufb01cation of the GHZ MPS\npresented above and then use Q to build our state of interest.\n6.2\nExtending to Higher Dimensions\nThe extension from one to higher dimensional systems proceeds straightforwardly. We will discuss the\nsimple case of a hypercubic lattice, but the framework can be carried out on any graph. In particular,\nwe will restrict to 2D.\n41\n", "44": "As before, we allow |\u03c6\u27e9to be some entangled pair. The PEPS is built as the natural generalisation\nto 2D\n|\u03c8\u27e9=\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\n,\n(6.7)\nwhere\nP :\n\u0000CD\u0001\u22974 \u2192Cd\n(6.8)\nis some linear operator from the virtual to the physical space.\nClearly there is a large amount of gauge freedom in this description as there was in the 1D case.\nAny invertible transformation of each virtual spin can be compensated in the de\ufb01nition of the PEPS\n\u2018projector\u2019 P, analogous to Eq. (6.4).\nAs in the MPS, one may ask whether using di\ufb00erent entanglement structures leads to greater\ndescriptive power. It is easy to see that this is not the case in general. Suppose we choose to lay down\nplaquettes in a GHZ state and then act with PEPS projectors between plaquettes.\n|\u03c8\u27e9=\n,\nwhere\n=\nX\ni\n\f\f\f\f\ni\ni\ni\ni\n\u001d\n.\n(6.9)\nWe can use a standard PEPS to prepare this resource state, so any state which can be prepared from\nthis \u2018projected entangled plaquette\u2019 construction can be prepared from a PEPS at small additional\ncost.\n6.3\nSome PEPS examples\nWe will now look at several example PEPs.\nProduct State\nWe have already seen this example in 1D. Exactly the same thing works in 2D, for example take\nP = |0\u27e9\n\u001c\n0\n0\n0\n0\n\f\f\f\f .\n(6.10)\n42\n", "45": "GHZ State\nDirectly generalising the 1D case, we can use\nP = |0\u27e9\n\u001c\n0\n0\n0\n0\n\f\f\f\f + |1\u27e9\n\u001c\n1\n1\n1\n1\n\f\f\f\f\n(6.11)\nto build the GHZ state.\nRVB State\nLet D = 3 be the bond dimension and let\n2\n2\n2\n\u03b1\n\u03b1\n= 1\n(6.12)\nfor \u03b1 \u2208{1, 2}, as well as all rotations on the virtual level, be the only nonzero elements of the PEPS\ntensor. Suppose we tile these tensors and project the dangling indices onto the |2\u27e9state. What is the\nresulting physical state?\nThis state is known as the resonating valence bond state [2\u20134] and consists of a superposition of\nall complete tilings of the lattice with maximally entangled pairs\n\f\f\f\f\f\n+\n+\n\f\f\f\f\f\n+\n+\n\f\f\f\f\f\n+\n+\n\f\f\f\f\f\n+\n+ \u00b7 \u00b7 \u00b7 ,\nwhere\n= |00\u27e9+ |11\u27e9.\nAside 3 : Kitaev\u2019s Toric code\nKitaev\u2019s Toric code [5] is a canonical example of a topologically ordered model Here we\nwill construct a Hamiltonian with the code space as the ground space of the model. The ground\nstate of this Hamiltonian is the superposition of all closed loops of \ufb02ipped spins.\nWe place qubits on the edges of a square lattice.\nWe wish to create a Hamiltonian with closed loop states (of \ufb02ipped spins) as the ground state.\nSuppose all spins are initially in the |0\u27e9state. Then around every vertex v place an interaction\nAv = \u2212\nZ\nZ\nZ\nZ\n.\n(6.13)\nTo be in the ground state of this term, the number of edges \ufb02ipped to |1\u27e9neighbouring a given\nvertex must be even. Drawing edges carrying \ufb02ipped spins in red, we can trace the e\ufb00ect of this\n43\n", "46": "on the lattice\n.\nWe can see that on a square graph, requiring an even number of edges incident on each vertex\nenforces that all of our loops are closed.\nAt this point, our ground space contains all states with only closed loops.\nWe want an\nequal superposition of all closed loop states. This is achieved by placing an interaction around\nplaquettes or squares on the lattice, which convert between loop states. To be an eigenstate, all\nloop states reachable from the vacuum state must be in the superposition. At each plaquette p,\nplace an interaction\nBp = \u2212\nX\nX\nX\nX\n.\n(6.14)\nThis has the desired e\ufb00ect.\nPlacing the interaction at the indicated plaquette performs the\nfollowing transformation of loops\n\u22c6\n\u2192\n\u22c6\n\u2192\n\u22c6\n\u2192\n.\nIt\u2019s not hard to convince yourself that all loop states can be reached from the empty state, so all\nclosed loop patterns must be in the superposition. The \ufb01nal Hamiltonian is\nHTC = \u2212\nX\nv\u2208vertices\nZ\nZ\nZ\nZ\n\u2212\nX\np\u2208plaquettes\nX\nX\nX\nX\n(6.15)\nand the ground state is an equal superposition over all closed loop states:\n\f\f\f\nE\n+\n\f\f\f\nE\n+\n\f\f\f\f\f\n+\n+\n\f\f\f\f\n\u001d\n+\n\f\f\f\f\f\n+\n+ \u00b7 \u00b7 \u00b7\n(6.16)\nNote that the Toric code Hamiltonian is usually presented in the |+\u27e9/|\u2212\u27e9basis rather than the\n|0\u27e9/|1\u27e9basis.\nToric code ground state\nThe simplest way to construct a PEPS for the toric code uses the structure of the ground state.\nThe PEPS tensor is constructed to ensure the superposition of closed loop patterns is achieved upon\ncontraction. The most natural way to achieve this it to write a single tensor for every second plaquette\nrather than each site.\nWe begin by adding new edges to the lattice. These edges will become the bonds in the tensor\nnetwork.\n44\n", "47": "1 2 3 4\n5 6 7 8\n9 10 11 12\n13 14 15 16\n17 18 19 20\n21 22 23 24\n\u2192\n1\n2\n5\n3\n4\n7\n6\n8\n9\n10\n13\n11\n12\n15\n14\n16\n17\n18\n21\n19\n20\n23\n22\n24\n,\nwhere the plaquettes are numbered for clarity.\nRecall that the ground state is built using loops of |1\u27e9in a background of |0\u27e9. We choose the state\nof the added edges such that the loop pattern is preserved\n\u2192\n,\nwhere\nindicates a spin in the |1\u27e9state on that edge. We choose the following convention when it\nis ambiguous\n\u2192\n,\nwhich makes everything consistent.\nInterpreting these added edges as bonds in a tensor network, we obtain a PEPS tensor for every\nsecond plaquette in the original lattice with four physical indices. The nonzero components are\ni + j\nk + l\nl + i\nj + k\ni\nj\nk\nl\n= 1,\n(6.17)\n45\n", "48": "where i, j, k, l \u2208Z2. In this tensor the straight legs indicate virtual indices, and the wavy legs physical\nindices, speci\ufb01cally the four qubits on the given plaquette. The network looks as below, with the\ndotted lines representing the original lattice:\n(6.18)\nThis tensor simply ensures that if adjacent physical indices are in the |1\u27e9state, i.e. carrying a\nloop, then the virtual index between them does not carry a loop which would leave the plaquette.\nConversely, if only one is in the |1\u27e9state, the loop must leave the plaquette.\nSince an even number of the virtual bonds must be in the |1\u27e9state for the tensor entry to be\nnonzero, the PEPS tensor has a property called G-injectivity [6]. This means that there is a symmetry\non the virtual level\nZ\nZ\nZ\nZ\n=\n.\n(6.19)\nThis turns out to be closely related to the topological order present in this model.\n6.4\n2D Cluster State and the complexity of PEPS\nLet D = 2 be the bond dimension and let\n\u03b1\n\u03b1\n\u03b2\n\u03b3\n\u03b1\n=\n(\n1,\nif \u03b1 = 0\n(\u22121)\u03b2+\u03b3,\nif \u03b1 = 1\n(6.20)\nbe the only nonzero elements of the PEPS tensor. The physical state generated is the 2D cluster state,\na universal resource for measurement based quantum computing [7,8].\nIf we could e\ufb03ciently take the inner product between PEPS (i.e. contract a square grid network),\nthen we can clearly classically simulate single qubit post selected measurements by simply contracting\nrank 1 projectors onto the physical indices of these PEPS tensors. This shows us that we cannot\ncontract even simple PEPS states e\ufb03ciently, unless post-selected quantum computing can be classically\nsimulated (Post-BQP=BPP) [9].\n6.4.1\nNumerical PEPS\nAlthough we will not discuss the details of numerical implementation of PEPS algorithms, we note\nthat the status is not as dire as the previous section would imply.\nIn many practical situations,\napproximate contraction of PEPS networks can be achieved in both the \ufb01nite [10] and in\ufb01nite [11,12]\nsystem size limits.\n46\n", "49": "6.5\nProperties of PEPS\nAbove, we saw a number of properties of 1D PEPS or MPS. We will now see which properties hold in\ntwo dimensions. One might na\u00a8\u0131vely expect MPS and more general PEPS to share similar properties.\nAs we will see below, these two tensor network states share qualitatively di\ufb00erent properties, both in\nterms of the physics the corresponding states exhibit, and in the computational power of the tensor\nnetworks.\nAside 4 : Tensor network for classical partition function\nLet H[s] = P\n\u27e8i,j\u27e9h[si, sj] be some classical Hamiltonian. We frequently want to calcu-\nlate the partition function Z = P\n{s} e\u2212\u03b2H[s] for such a system at a temperature \u03b2. We can use\na simple tensor network to help.\nDe\ufb01ne the two tensors\ni\nj\nk\nl\nD\n= \u03b4i,j,k,l,\ni\nj\nM\n= e\u2212\u03b2h[si,sj].\n(6.21)\nPlacing a D tensor at every classical spin and an M tensor corresponding to each interaction,\nthe following network evaluates to the partition function.\nZ =\n(6.22)\nThermal expectation values can be calculated by inserting local tensors into this network. For\nexample\nZ \u00d7 \u27e8sn\u27e9=\nX\n{s}\nsne\u2212\u03b2H[s] =\n,\n(6.23)\nwhere\n= \u03c3Z,\n(6.24)\nhas been inserted at site n.\nNotice that by combining D and M tensors, the partition function can be described with a\n47\n", "50": "single tensor\ni\nj\nk\nl\nQ\n=\nX\nsa\ne\u2212\u03b2\n2 (h[si,sa]+h[sj,sa]+h[sk,sa]+h[sl,sa]).\n(6.25)\nLet\nH = \u2212J\nX\n\u27e8i,j\u27e9\nsisj,\n(6.26)\nwhere s \u2208{\u00b11}, the classical Ising model. The tensor Q then simpli\ufb01es to\ni\nj\nk\nl\nQ\n= 2 cosh\n\u0012\u03b2J\n2 (si + sj + sk + sl)\n\u0013\n.\n(6.27)\n6.5.1\nAlgebraic decay of correlations\nAs we saw above, MPS can only capture states with exponential decay of correlations (or constant\ncorrelations of course). We will now see if this holds in the case of PEPS. We can build a PEPS state\ncorresponding to a classical partition function by modifying the above construction [3]. Let\ni\nj\nk\nl\nx\nD\n= \u03b4i,j,k,l,x,\ni\nj\nM\n= e\u2212\u03b2\n2 h[si,sj],\n(6.28)\nor equivalently combine these into\ni\nj\nk\nl\nx\nQ\n= e\u2212\u03b2\n4 (h[si,sx]+h[sj,sx]+h[sk,sx]+h[sl,sx]).\n(6.29)\nThis de\ufb01nes a PEPS state\n|\u03c8\u27e9=\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\nQ\n.\n(6.30)\nNote this is a pure state, and not a thermal state. It is however not normalised, with \u27e8\u03c8|\u03c8\u27e9= Z.\nCorrelation functions computed using this state are equal to those computed using classical statistical\n48\n", "51": "physics.\nSuppose we were to consider a classical model with a thermal phase transition (such as\nthe Ising model above).\nSuch a model will exhibit algebraic decay of correlations at the critical\ntemperature, implying that the corresponding PEPS does as well. Thus we can see that unlike MPS,\nthe states described by PEPS can exhibit algebraic decay of correlations.\n6.5.2\nGauge freedom\nThe gauge freedom of a PEPS tensor is a simple generalisation of the MPS freedom. As before, we can\nblock tensors together without changing the global state. In addition, we can perform the following\ntransformation (on a translationally invariant PEPS):\n\u2192\nM\u22121\nM\nN\u22121\nN\n,\n(6.31)\nwhere N and M are invertible matrices.\nRecall that in the MPS case, we could use this freedom to bring the tensors into a canonical form.\nThis cannot be done exactly in the case of PEPS, though there do exist numerical methods to bring\nPEPS into approximate canonical forms [13].\nProblems 6\nSolutions in accompanying document.\n1. What is the PEPS tensor required to build the GHZ state on the honeycomb lattice where\nspins reside on vertices?\n2. Which 2 qubit gate is obtained by contracting the following tensors along the horizontal\nindex?\nu\ni\nj\nk\n= \u03b4i,j\n\u0000\u03b4k,0 + (\u22121)i\u03b4k,1\n\u0001\n,\nv\nx\ny\nz\n= \u03b4x,y,z.\n(6.32)\n3. The cluster state can be prepared from the all |+\u27e9state by applying CZ between all adjacent\nspins. Show that Eq. (6.20) indeed gives the cluster state.\nHint: Consider the decomposition of a gate given in the above problem.\n4. Investigate how logical operators on the physical spins of the Toric code can be pulled onto\nthe virtual level of the PEPS. Can you see why G-injectivity is so important for topologically\nordered PEPS?\n5. Convince yourself that evaluating expectation values on the PEPS constructed from a\nclassical partition function indeed reproduces the thermal expectation values.\n6.7\nReferences\n[1] F. Verstraete, J. I. Cirac, and V. Murg, \u201cMatrix Product States, Projected Entangled Pair States, and variational\nrenormalization group methods for quantum spin systems,\u201d Advances in Physics 57, 143\u2013224, arXiv:0907.2796,\n(2009).\n49\n", "52": "[2] R. Or\u00b4us, \u201cA practical introduction to tensor networks: Matrix product states and projected entangled pair states,\u201d\nAnnals of Physics 349, 117\u2013158, arXiv:1306.2164, (2014).\n[3] F. Verstraete, M. M. Wolf, D. Perez-Garcia, and J. I. Cirac, \u201cCriticality, the area law, and the computational power\nof projected entangled pair states.,\u201d Physical Review Letters 96, 220601, arXiv:quant-ph/0601075, (2006).\n[4] N. Schuch, D. Poilblanc, J. I. Cirac, and D. P\u00b4erez-Garc\u00b4\u0131a, \u201cResonating valence bond states in the PEPS formalism,\u201d\nPhysical Review B 86, 115108, arXiv:1203.4816, (2012).\n[5] A. Y. Kitaev, \u201cFault-tolerant quantum computation by anyons,\u201d Annals of Physics 303, 2\u201330, arXiv:quant-\nph/9707021, (2003).\n[6] N. Schuch, I. Cirac, and D. P\u00b4erez-Garc\u00b4\u0131a, \u201cPEPS as ground states: Degeneracy and topology,\u201d Annals of Physics\n325, 2153\u20132192, arXiv:1001.3807, (2010).\n[7] F. Verstraete and J. I. Cirac, \u201cValence-bond states for quantum computation,\u201d Physical Review A 70, 060302,\narXiv:quant-ph/0311130, (2004).\n[8] N. Schuch, M. Wolf, F. Verstraete, and J. Cirac, \u201cEntropy Scaling and Simulability by Matrix Product States,\u201d\nPhysical Review Letters 100, 30504, arXiv:0705.0292, (2008).\n[9] N. Schuch, M. Wolf, F. Verstraete, and J. Cirac, \u201cThe computational complexity of PEPS,\u201d Physical Review Letters\n98, 140506, arXiv:quant-ph/0611050, (2008).\n[10] M. Lubasch, J. Cirac, and M.-C. Ba\u02dcnuls, \u201cAlgorithms for \ufb01nite projected entangled pair states,\u201d Physical Review\nB 90, 064425, arXiv:1405.3259, (2014).\n[11] J. Jordan, R. Orus, G. Vidal,F. Verstraete, and J. Cirac, \u201cClassical simulation of in\ufb01nite-size quantum lattice\nsystems in two spatial dimensions,\u201d Physical Review Letters 101, 250602, arXiv:cond-mat/0703788, (2008).\n[12] H. N. Phien, J. A. Bengua, H. D. Tuan, P. Corboz, and R. Orus, \u201cThe iPEPS algorithm, improved: fast full update\nand gauge \ufb01xing,\u201d Physical Review B 92, 035142, arXiv:1503.05345, (2015).\n[13] D. P\u00b4erez-Garc\u00b4\u0131a, M. Sanz, C. E. Gonz\u00b4alez-Guill\u00b4en, M. M. Wolf, and J. I. Cirac, \u201cCharacterizing symmetries in a\nprojected entangled pair state,\u201d New Journal of Physics 12, 025010, arXiv:0908.1674, (2010).\n50\n", "53": "7\nMultiscale Entanglement Renormalisation Ansatz\nMPS are extremely useful for understanding low energy states of 1D quantum models. Despite this,\nthey cannot capture the essential features of some important classes of states. In particular, they\ncannot reproduce the correlations seen in gapless ground states. Recall that MPS always have expo-\nnentially decaying correlations, whereas gapless ground states generically support correlations with\npower law decay. Similarly MPS also have a strict area law for entanglement entropy, where gapless\nstates admit a logarithmic divergence. The multiscale entanglement renormalisation ansatz is a tensor\nnetwork designed to overcome these problems.\nAs mentioned in lecture 5, although MPS do not naturally support the kind of correlations expected\nin critical models, they have been successfully applied for the study of such systems nonetheless. Using\nMPS for this purpose requires a family of MPS of increasing bond dimension to examine how the\ncorrelations behave. The MERA state functions di\ufb00erently. As we will discuss, a single MERA state\ncan naturally capture the physics of a gapless ground state.\nHere, we will present the tensor network as an ansatz and argue that it is well suited to representing\nground states of gapless Hamiltonians in 1D. Suppose the state can be written as\n|\u03c8\u27e9=\n,\n(7.1)\nwhere\nu\nu\u2020\n=\n,\nw\nw\u2020\n=\n.\n(7.2)\nAs we will see, these constraints on the tensors have both a physical and computational impact.\nNote that the u and w tensors do not have to be identical, although we frequently restrict to this\ncase if we expect translationally and scale invariant states. The class of states which are expressed as\nEqn. 7.1 are known as Multiscale Entanglement Renormalisation Ansatz (MERA) states [1\u20135].\nAlthough we will not discuss it here, the MERA can be straightforwardly generalised to higher\ndimensional systems [6\u20139]. Unlike PEPS, the network can be e\ufb03ciently optimised in higher dimensions,\nalthough the scaling makes the numerics very challenging!\n7.1\nProperties of MERA\nLogarithmic violation of the area law\nOne of the key properties realised in the MERA which cannot be realised in MPS is a scaling of\nentanglement entropy. This is easily seen by bond counting. Recall that if n bonds must be broken\nto separate a region from the rest of the network, the maximum entanglement entropy that can be\nsupported is n log D, where D is the bond dimension. Recall that in the case of MPS any reduced\nstate on a contiguous region can be removed by cutting n = 2 bonds.\nBy inspecting the diagram\nN\n,\n(7.3)\n51\n", "54": "it is straightforward to see that to remove a block of N physical indices from the rest of the network,\nO(log N) bonds must be cut. This shows that the maximum entropy scales as log N log D [1,2].\nPower law decay of correlations\nUsing the constraints on the tensors (Eqn. 7.2), we can simplify the evaluation of a two point correlator\non a MERA state [3].\n\u27e8\u03c8|OjOj+N|\u03c8\u27e9=\n(7.4)\n=\n(7.5)\n=\n(7.6)\n=\n.\n(7.7)\nNote that the length scale behaviour of the correlator is completely determined by the application\nof a superoperator\nS(\u03c6) =\n\u03c6\n,\n(7.8)\nwhere the w tensor can be viewed as a set of Kraus operators\nMk =\nk\n(7.9)\n52\n", "55": "obtained by grouping the indices indicated.\nThus, S is a completely positive, unital map and all eigenvalues \u03bb of S are |\u03bb| \u22641. We can bring\noperators separated by N sites together by applying S \u223clog N times. Considering eigenoperators of\nthe S superoperator, the correlator acts as\n\u27e8AjBk\u27e9\u223c\n\u27e8A0B1\u27e9\n|j \u2212k|\u2206A+\u2206B ,\n(7.10)\nwhere \u2206\u03c6 = \u2212log3 \u03bb\u03c6, \u2206\u03c6 \u22650 are known as scaling dimensions, where \u03bb\u03c6 is the corresponding\neigenvalue of S. Therefore, a MERA state can support algebraic decay of correlations. Although this\ndiscussion required the operators to be placed at special sites, it can be easily generalised.\nE\ufb03cient Manipulation\nAs described in Section 1.5, a good tensor network ansatz should ful\ufb01l two properties. First, it should\nbe e\ufb03ciently storable. All of the networks we have discussed thus far have this property, as only a\nsmall number of coe\ufb03cients are required to represent these states. The second property is more subtle;\none should be able to extract physical data e\ufb03ciently. Although this works for the 1D MPS network,\nit fails for 2D PEPS states; the contractions required to calculate expectation values of local operators\nis incredibly hard.\nIt turns out the MERA has both of these properties. One can e\ufb03ciently store the state data,\nand, thanks to the constraints in Eqn. 7.2, one can e\ufb03ciently compute local expectation values and\ncorrelators. We have already seen how this works. The isometric constraints ensure that local operators\non the physical level of the network are mapped to local operators on the higher levels [10]. Therefore,\ncomputing expectation values only requires manipulation of a small number of tensors in the causal\ncone of the operator\n\u27e8O\u27e9=\n,\n(7.11)\nwhere the shaded region indicates the causal cone of the \ufb01ve site operator on the physical level indicated\nin yellow. Notice that the number of tensors on each subsequent level does not grow. Indeed, after a\nsingle layer of tensors, the operator becomes a three site operator, and the range never grows. Thus,\nwe see that the layers of the MERA act to map local operators to local operators.\n7.2\nRenormalisation Group Transformation\nMuch of the discussion above concerned interpretation of the layers of the MERA as Kraus operators,\nde\ufb01ning a unital CP map on local operators. Evaluating expectation values can be seen as application\nof many superoperators followed by the inner product with some state on a smaller number of sites\n\u27e8\u03c80|O|\u03c80\u27e9= \u27e8\u03c8k+1|Ak \u25e6\u00b7 \u00b7 \u00b7 \u25e6A1 \u25e6A0(O)|\u03c8k+1\u27e9,\n(7.12)\nwhere Aj is a map from 3N\u2212j spins to 3N\u2212j/3 spins. This can be seen as a renormalisation group\nor scale transformation. The state |\u03c8j\u27e9is supported on 3N\u2212j spins, and contains only the physical\ndata necessary to understand the physics on that length scale. As we saw, if O is a local operator,\n53\n", "56": "A(O) is easy to evaluate. This allows us to understand the e\ufb00ective operator as a function of length\nscale [1,3,4].\nThe thermodynamic or macroscopic observables can be seen as the operators obtained by applying\na formally in\ufb01nite number of MERA layers to the high energy or microscopic observables. Thus,\nthe macroscopic physics, or phase structure, is determined by \ufb01xed points of the maps A.\nSome\nparticularly interesting states are the scale invariant states. If the MERA tensors are all the same\nafter some layer, the state is scale invariant. For these states, we do not expect the physics to change\nas a function of length or energy scale. The \ufb01xed point observables of these states are particularly\nsimple to understand, and distinct scale invariant states characterise the di\ufb00erent phases.\nSince there is no characteristic length scale set by either the spectral gap or correlation length,\ngapless ground states are expected to be scale invariant. The MERA therefore allows us to understand\nthe long range physics of these states incredibly e\ufb03ciently [3, 10]. Another way to achieve a scale\ninvariant state is to have zero correlation length \u2014 these states characterise gapped phases.\n7.3\nAdS/CFT\nIn the appropriate limit, the low energy physics of the gapless spin chains considered here is described\nby a conformal \ufb01eld theory (CFT) [12,13]. The physics of CFTs is thought to be related to gravitational\ntheories in one additional dimension [14\u201316].\nThis duality can be observed in the MERA network [17\u201319]. Imposing the graph metric on the\nMERA, we \ufb01nd a discretised anti-de Sitter (AdS) metric [17], whilst the edge theory is a \u2018discretised\u2019\nCFT. In addition to being a concrete realisation of the holographic principle, the MERA/CFT duality\nprovides avenues towards designing quantum error correcting codes [20].\nWe note that the AdS/MERA connection remains an open research question.\nLimits on the\nability of MERA states to replicate physics on scales less than the AdS radius have been shown [19].\nAdditionally, whether the geometry is best understood as anti-de Sitter [17] or de Sitter [18] is currently\nunclear. Whatever the status, the connection is intriguing. We encourage the interested reader to\nexplore the rapidly expanding literature on the topic [19\u201328].\n7.4\nSome Simple MERA States\nProduct State\nLet\nw =\n0\n1\n\uf8eb\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ec\n\uf8ed\n\uf8f6\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f7\n\uf8f8\n000\n1/2\n0\n100\n1/2\n0\n010\n0\n1/2\n110\n0\n1/2\n001\n1/2\n0\n101\n1/2\n0\n011\n0\n1/2\n111\n0\n1/2\n(7.13)\nand u = 1.\nIf we build log3 N layers using these tensors, we end up with a state on N sites. The network still\nhas a free index at the top, so we need to de\ufb01ne a one-index \u2018top tensor\u2019 T to obtain the \ufb01nal state.\nLet T = |+\u27e9. The state obtained is |+\u27e9\u2297N.\n54\n", "57": "GHZ State\nLet\nj\nl\ni\nk\n= \u03b4i,j,k,l,\n(7.14)\nand u = 1. Let the top tensor be T = |+\u27e9. The state obtained is |0\u27e9\u2297N+|1\u27e9\u2297N\n\u221a\n2\n.\nCluster State\nIt is more convenient to de\ufb01ne the cluster state on a binary MERA than a ternary. Place two spins\nat each site and let\n=\nH\n,\n(7.15)\nwhere\nis a controlled-Z gate and H is the Hadamard. If we pick a top tensor T = |++\u27e9, we\nobtain the cluster state on periodic boundary conditions.\nGapless states\nRecently, a family of analytic MERA for the critical point of the transverse \ufb01eld Ising model was\nproposed [11]. One can also use numerical techniques to obtain a MERA approximation to the ground\nstate of a local Hamiltonian however. Here, we will present some physical data obtained for a model\nknown as the transverse \ufb01eld cluster model [29]. In particular, we will present the ground state energy\nand the decay exponents (\u2206\u03c6 in Eqn. 7.10).\nThis model is most straightforwardly de\ufb01ned with a pair of spin half particles at each site. The\nHamiltonian for this model is\nH = \u2212\nX\nj\n\u0010\nX(1)\nj\n+ X(2)\nj\n+ Z(2)\nj\u22121X(1)\nj\nZ(2)\nj\n+ Z(1)\nj X(2)\nj\nZ(1)\nj+1\n\u0011\n\u2212\u03bb\nX\nj\n\u0010\nX(1)\nj\nX(2)\nj\n+ Z(1)\nj Y (2)\nj\nY (1)\nj+1Z(2)\nj+1\n\u0011\n.\n(7.16)\n\u22121\n\u221a\n2\u22121\n2\n0\n1\n2\n1\n\u22123.5\n\u22123\n\u22122.5\n\u22122\n\u03bb\nE0\nMERA\nExact\na)\n\u22121\n\u221a\n2\u22121\n2\n0\n1\n2\n1\n0\n1/2\n1\n3/2\n2\n\u03bb\n\u2206\u03c6\nMERA\nExact\nb)\nFigure 1: a) Ground state energy density extracted from a ternary MERA after optimising the tensors to\nlocally minimise the energy.\nb) Correlation decay exponents for the transverse \ufb01eld cluster model obtained from a ternary MERA.\nFigures reproduced from Ref. [29].\n55\n", "58": "This is the cluster state Hamiltonian with transverse \ufb01elds and an additional interaction with variable\nstrength. The Hamiltonian remains gapless for a range of values of \u03bb, over which the ground state\nenergy varies continuously as seen in Fig. 1a). The decay exponents also vary over this range, meaning\nthat the thermodynamic physics or RG \ufb01xed point is dependent on \u03bb. These exponents can easily be\nextracted from an optimised MERA by \ufb01nding the eigenvalues of the S superoperator in Eqn. 7.8.\nThe MERA results are shown in Fig. 1b).\nProblems 7\nSolutions in accompanying document.\n1. Can you \ufb01nd a MERA for the W state?\n2. What state is given by the MERA with\n=\n,\n(7.17)\nu = 1 and top tensor T =\n1\n\u221a\n2(|00\u27e9+ |11\u27e9)?\n3. The above state is the ground state of the Hamiltonian\nH = \u2212\nN/2\nX\nj=1\n(X2jX2j+1 + Z2jZ2j+1)\n(7.18)\non periodic boundary conditions. Is that clear? Can you \ufb01nd a unitary U2j\u22121,2j which\ntransforms this Hamiltonian into\nH = \u2212\nN/2\nX\nj=1\n(Z2j\u22121X2jZ2j+1 + Z2jX2j+1Z2j+2)?\n(7.19)\n4. Act with the above transformation U on the MERA tensor to obtain another MERA tensor.\nWhat is this state?\n5. What is the maximum range of thermodynamic observables in a ternary MERA scheme?\n6. What does the reduced density matrix on a few sites of the MERA look like? Notice that\nit corresponds to the top tensor being passed through a CPTP map several times, this is\nusually called the descending superoperator.\n7. Do tree tensor networks (i.e. MERA for u = 1) have any area law violation on contiguous\nregions?\n7.6\nReferences\n[1] G. Vidal, \u201cEntanglement renormalization,\u201d Physical Review Letters 99, 220405, arXiv:cond-mat/0512165, (2007).\n[2] G. Vidal, \u201cClass of Quantum Many-Body States That Can Be E\ufb03ciently Simulated,\u201d Physical Review Letters 101,\n110501, arXiv:quant-ph/0610099, (2008).\n[3] R. N. C. Pfeifer, G. Evenbly, and G. Vidal, \u201cEntanglement renormalization, scale invariance, and quantum criticality,\u201d\nPhysical Review A 79, 040301, arXiv:0810.0580, (2009).\n[4] G. Evenbly and G. Vidal, \u201cAlgorithms for entanglement renormalization,\u201d Physical Review B 79, 149903,\narXiv:1201.1144, (2009).\n56\n", "59": "[5] G. Vidal, \u201cEntanglement Renormalization: An Introduction,\u201d in Understanding quantum phase transitions (L. Carr,\ned.), ch. 5, p. 115\u2013138, CRC Press, arXiv:0912.1651, (2011).\n[6] G. Evenbly and G. Vidal, \u201cEntanglement renormalization in fermionic systems,\u201d Physical Review B 81, 235102,\narXiv:0710.0692, (2010).\n[7] L. Cincio, J. Dziarmaga and M. M. Rams, \u201cMulti-scale Entanglement Renormalization Ansatz in Two Dimensions:\nQuantum Ising Model,\u201d Physical Review Letters 100, 240603, arXiv:0710.3829, (2008).\n[8] M. Aguado and G. Vidal, \u201cEntanglement renormalization and topological order,\u201d Physical Review Letters 100,\n070404, arXiv:0712.0348, (2008).\n[9] G. Evenbly and G. Vidal, \u201cEntanglement renormalization in two spatial dimensions,\u201d Physical Review Letters 102,\n180406, arXiv:0811.0879, (2009).\n[10] G. Evenbly and G. Vidal, \u201cQuantum Criticality with the Multi-scale Entanglement Renormalization Ansatz,\u201d in\nStrongly Correlated Systems. Numerical Methods (A. Avella and F. Mancini, ed.), ch. 4, Springer, arXiv:1109.5334,\n(2013).\n[11] G. Evenbly and S. R. White, \u201cEntanglement renormalization and wavelets,\u201d Physical Review Letters 116, 140403,\narXiv:1602.01166, (2016).\n[12] P. Di Francesco, P. Mathieu and D. S\u00b4en\u00b4echal, Conformal Field Theory. Springer, (1997).\n[13] P. Christe and M. Henkel, Introduction to Conformal Invariance and Its Applications to Critical Phenomena.\nSpringer-Verlag, (1993).\n[14] J. M. Maldacena, \u201cThe Large N Limit of Superconformal Field Theories and Supergravity,\u201d International Journal\nof Theoretical Physics 38, 1113, arXiv:hep-th/9711200, (1998).\n[15] E. Witten, \u201cAnti De Sitter Space And Holography,\u201d Advances in Theoretical and Mathematical Physics 2, 253,\narXiv:hep-th/9802150, (1998).\n[16] S. S. Gusber, I. R.. Klebanov and A. M. Polyakov \u201cGauge theory correlators from non-critical string theory,\u201d\nPhysics Letters B 428, 105, arXiv:hep-th/9802109, (1998).\n[17] B. Swingle, \u201cEntanglement Renormalization and Holography,\u201d Physical Review D 86, 065007, arXiv:0905.1317,\n(2012).\n[18] C. B\u00b4eny, \u201cCausal structure of the entanglement renormalization ansatz,\u201d New Journal of Physics 15, 023020,\narXiv:1110.4872, (2013).\n[19] N. Bao, C. Cao, S. M. Carroll and A. Chatwin-Davies, \u201cConsistency Conditions for an AdS/MERA Correspon-\ndence,\u201d Physical Review D 91, 125036, arXiv:1504.06632, (2015).\n[20] F. Pastawski, B. Yoshida, D. Harlow and J. Preskill, \u201cHolographic quantum error-correcting codes: Toy models for\nthe bulk/boundary correspondence,\u201d Journal of High Energy Physics 6, 149, arXiv:1503.06237, (2015).\n[21] G. Evenbly and G. Vidal, \u201cTensor network states and geometry,\u201d Journal of Statistical Physics 145, 891,\narXiv:1106.1082, (2011).\n[22] M. Nozaki, S. Ryu, and T. Takayanagi, \u201cHolographic Geometry of Entanglement Renormalization in Quantum\nField Theories,\u201d Journal of High Energy Physics 2012, 193, arXiv:1208.3469, (2012).\n[23] B. Swingle, \u201cConstructing holographic spacetimes using entanglement renormalization,\u201d arXiv:1209.3304, (2012).\n[24] T. Hartman and J. Maldacena, \u201cTime Evolution of Entanglement Entropy from Black Hole Interiors,\u201d Journal of\nHigh Energy Physics 2013, 014, arXiv:1303.1080, (2013).\n[25] M. Miyaji, S. Ryu, T. Takayanagi, and X. Wen, \u201cBoundary States as Holographic Duals of Trivial Spacetimes,\u201d\nJournal of High Energy Physics 2015, 152, arXiv:1412.6226, (2015).\n[26] M. Miyaji and T. Takayanagi, \u201cSurface/State Correspondence as a Generalized Holography,\u201d Progress of Theoretical\nand Experimental Physics 2015, 073B03, arXiv:1503.03542, (2015).\n[27] M. Miyaji, T. Numasawa, N. Shiba, T. Takayanagi, and K. Watanabe, \u201ccMERA as Surface/State Correspondence\nin AdS/CFT,\u201d Physical Review Letters 115, 171602, arXiv:1506.01353, (2015).\n[28] W. -C. Gan, F. -W. Shu, and M. -H. Wu, \u201cThermal geometry from CFT at \ufb01nite temperature,\u201d Physics Letters B\n750, 796, arXiv:1506.01353, (2015).\n[29] J. C. Bridgeman, A. O\u2019Brien, S. D. Bartlett, and A. C. Doherty, \u201cMultiscale entanglement renormalization ansatz\nfor spin chains with continuously varying criticality,\u201d Physical Review B 91, 165129, arXiv:1501.02817, (2015).\n57\n", "60": "A\nPEPOs for local Hamiltonians: The \u2018particle decay\u2019 construction\nIn numerical algorithms such as DMRG, operators such as Hamiltonians are often represented in the\nform of Matrix Product Operators (MPO) in 1D, and Projected Entangled Pair Operators (PEPO)\nin 2D and higher, as seen below. For highly structured Hamiltonians, such as those which are local\nand translation invariant, an analytic MPO construction of such operators is known in 1D [1]. In\nthis section we review this, and outline a generalisation which allows for local Hamiltonians (and\neven slightly less structured operators) to be optimally expressed as a PEPOs in arbitrary spatial\ndimensions.\nMuch like in Eqs. (3.54) and (3.58) we are going to omit the physical indices, as such we will\nconsider MPO tensors to be (operator-valued) matrices, and PEPO tensors to be (operator-valued)\nrank-2D tensors in D spatial dimensions.\nIn this section we will need to specify individual tensor values, as well as the values of a tensor\nnetwork for a speci\ufb01c index designation. For brevity, we will therefore omit the legs in our diagrams,\nindicating speci\ufb01c entries in a tensor by a \u25a0\u25a1surrounded by the index values. For example the identity\nis given by i \u25a0\u25a1i = 1 for all i. To make the constructions more clear we will also allow for non-numeric\nindex values, and denote the index set by I.\nA.1\n1D\nIn this notation, if we label our indices I = {\u00b7, 1, \u2192}, then the transverse Ising model Hamiltonian\ngiven in Eq. (3.54) is given by\n\u00b7 \u25a0\u25a1\u00b7 = \u2192\u25a0\u25a1\u2192= 1\n(A.1)\n\u2192\u25a0\u25a1\u00b7 = \u2212hZ\n\u2192\u25a0\u25a11 = X\n1 \u25a0\u25a1\u00b7 = \u2212JX\n(A.2)\nwhere the boundary terms \ufb01x the far left and right indices to |\u2192\u27e9and |\u00b7\u27e9respectively.\nOne common interpretation of this construction is in terms of \ufb01nite-state automata, with the index\nvalues corresponding to the automaton states, and the non-zero index values to the transition rules.\nThe automaton moves from left to right13 , with the boundary vectors setting the initial state to |\u2192\u27e9\nand \ufb01nal state to |\u00b7\u27e9. With only these restrictions, the automaton can transition from |\u2192\u27e9to |\u00b7\u27e9either\ndirectly (giving the \ufb01eld term \u2212hZ), or via 1 (giving the Ising term \u2212JXX) at any location.\nTo make the higher dimensional generalisation clear we will slightly modify this \ufb01nite-state au-\ntomata language, to that of particles and their decay. We can think of \u2192as a right-moving particle,\nand \u00b7 as the vacuum. The \ufb01rst two transition rules (A.1) correspond to both the vacuum and particle\nbeing stable states, with the remaining transitions (A.2) to valid decay routes of the particle. Thus\nwe can interpret the value of the overall MPO as being a superposition over all decays, with each\ncorresponding to a term in the Hamiltonian.\nHeisenberg Model\nSuppose we wish to construct a Hamiltonian containing multiple two-body terms, such as the Heisen-\nberg anti-ferromagnet, which contains the terms \u2212JXXX, \u2212JY Y Y , \u2212JZZZ, as well as a \ufb01eld \u2212hZ.\nAn MPO of this model is given in standard notation in Eq. (3.58).\n13Though a right-to-left convention is more commonly used in this 1D construction, a left-to-right convention will\nprove useful for consistency with the higher dimensional construction.\n58\n", "61": "Added Hamiltonian terms can be accommodated in this construction by extra decay chains. Take\nour index set to be I = {\u00b7, x, y, z, \u2192} and our MPO to have terms:\n\u00b7 \u25a0\u25a1\u00b7 = 1\n\u2192\u25a0\u25a1\u2192= 1\n(A.3)\n\u2192\u25a0\u25a1x = X\nx \u25a0\u25a1\u00b7 = \u2212JXX\n(A.4)\n\u2192\u25a0\u25a1y = Y\ny \u25a0\u25a1\u00b7 = \u2212JY Y\n(A.5)\n\u2192\u25a0\u25a1z = Z\nz \u25a0\u25a1\u00b7 = \u2212JZZ\n(A.6)\n\u2192\u25a0\u25a1\u00b7 = \u2212hZ\n(A.7)\nAgain Equations A.3 correspond to stable vacuum and particles, and each of the transition rules\nEqs. (A.4) to (A.7) to each term in the Hamiltonian.\nCluster Model\nThe Cluster Hamiltonian contains three body terms of the form ZXZ. Larger terms such as this can\nbe accommodated by longer decay chains. Take an index set I = {\u00b7, 1, 2, \u2192} and include the standard\nstable vacuum/particle terms as well as\n\u2192\u25a0\u25a12 = Z\n2 \u25a0\u25a11 = X\n1 \u25a0\u25a1\u00b7 = Z.\n(A.8)\nBy combining the above two techniques, we can construct arbitrary local Hamiltonians.\nA.2\n2D and higher\nIn higher dimensions we can use a similar construction. Suppose we want to construct a 2D \ufb01eld\nHamiltonian, consisting of a Z at every site. Take our index set to be I = {\u2192, \u00b7}. Our typical stable\nvacuum/particle terms that we will always include now become\n\u00b7\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u00b7\n=\n\u00b7\n\u2192\u25a0\u25a1\u2192\n\u00b7\n= 1.\n(A.9)\nFor the \ufb01eld Hamiltonian we need only allow for a simple particle decay of\n\u00b7\n\u2192\u25a0\u25a1\n\u00b7\n\u00b7\n= Z\n(A.10)\nAs for the boundary conditions, along the top, right and bottom boundaries we will once again \ufb01x the\nonly non-zero indices to be the vacuum |\u00b7\u27e9. Along the left edge, the boundary condition is a virtual\nW-state (c.f. Eq. (3.18)) on indices {\u2192, \u00b7}, i.e. the equal superposition of all single-particle states. As\nsuch we can see that all the non-zero contributions to the Hamiltonian are of the form:\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u2192\n\u25a0\u25a1\n\u2192\n\u25a0\u25a1\n\u2192\n\u25a0\u25a1\n\u2192\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n=\n1\n1\n1\n1\n1\n1\n1\n1\nZ\n1\n1\n1\n1\n1\n1\nAs with 1D, by introducing intermediary states and di\ufb00erent decay rules, arbitrary local Hamil-\ntonians in any dimension can be similarly constructed. For example suppose we wanted a 9-body\nplaquette term of the form:\nJ\nK\nL\nM\nN\nO\nP\nQ\nR\n59\n", "62": "Take I = {\u00b7, 1, 2, \u2192} and our non-trivial decay modes to be\n\u00b7\n\u2192\n\u25a0\u25a1\n2\n2\n= J,\n\u00b7\n2\n\u25a0\u25a1\n1\n2\n= K,\n\u00b7\n1\n\u25a0\u25a1\n\u00b7\n2\n= L,\n2\n\u00b7\n\u25a0\u25a1\n1\n1\n= M,\n2\n2\n\u25a0\u25a1\n1\n1\n= N,\n2\n1\n\u25a0\u25a1\n\u00b7\n1\n= O,\n1\n\u00b7\n\u25a0\u25a1\n2\n\u00b7\n= P,\n1\n2\n\u25a0\u25a1\n1\n\u00b7\n= Q,\n1\n1\n\u25a0\u25a1\n\u00b7\n\u00b7\n= R.\nthen we can see that the non-zero contributions to the Hamiltonian are of the form\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u2192\n\u25a0\u25a1\n\u2192\n\u25a0\u25a1\n\u2192\n\u25a0\u25a1\n2\n\u25a0\u25a1\n1\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u00b7\n\u00b7\n2\n2\n2\n\u00b7\n\u00b7\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n2\n\u25a0\u25a1\n1\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u00b7\n\u00b7\n1\n1\n1\n\u00b7\n\u00b7\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n2\n\u25a0\u25a1\n1\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n\u00b7\n=\n1\n1\n1\n1\n1\n1\n1\n1\n1\nJ\nK\nL\n1\n1\n1\n1\nM\nN\nO\n1\n1\n1\n1\nP\nQ\nR\n1\n1\n1\n1\n1\n1\n1\n1\n1\nA.3\nOther examples\nBelow are several more example of Hamiltonian constructed by the above method.\nToric code (Wen Plaquette)\nI = {\u00b7, 1, \u2192}\n\u00b7\n\u2192\n\u25a0\u25a1\n1\n1\n=\n1\n1\n\u25a0\u25a1\n\u00b7\n\u00b7\n= X\n\u00b7\n1\n\u25a0\u25a1\n\u00b7\n1\n=\n1\n\u00b7\n\u25a0\u25a1\n1\n\u00b7\n= Y\nQuantum Compass model/Bacon-Shor code\nI = {\u00b7, 1, \u2192}\n\u00b7\n\u2192\n\u25a0\u25a1\n1\n\u00b7\n=\n\u00b7\n1\n\u25a0\u25a1\n\u00b7\n\u00b7\n= X\n\u00b7\n\u2192\n\u25a0\u25a1\n\u00b7\n1\n=\n1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u00b7\n= Y\n2D Transverse Ising\nI = {\u00b7, 1, \u2192}\n\u00b7\n\u2192\n\u25a0\u25a1\n\u00b7\n\u00b7\n= hZ\n\u00b7\n\u2192\n\u25a0\u25a1\n1\n\u00b7\n=\n\u00b7\n\u2192\n\u25a0\u25a1\n\u00b7\n1\n= JX\n\u00b7\n1\n\u25a0\u25a1\n\u00b7\n\u00b7\n=\n1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u00b7\n= \u2212X\n2D Cluster state\nI = {\u00b7, 1, 2, \u2192}\n\u00b7\n\u2192\n\u25a0\u25a1\n2\n\u00b7\n=\n\u00b7\n1\n\u25a0\u25a1\n\u00b7\n\u00b7\n=\n1\n\u00b7\n\u25a0\u25a1\n\u00b7\n\u00b7\n=\n\u00b7\n\u00b7\n\u25a0\u25a1\n\u00b7\n1\n= Z\n1\n2\n\u25a0\u25a1\n1\n1\n= X\nA.4\nReferences\n[1] U. Schollw\u00a8ock, \u201cThe density-matrix renormalization group in the age of matrix product states,\u201d Annals of Physics\n326, 96\u2013192, arXiv:1008.3477, (2011).\n60\n"}